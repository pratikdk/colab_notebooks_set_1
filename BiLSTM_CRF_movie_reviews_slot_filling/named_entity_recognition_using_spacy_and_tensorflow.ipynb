{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"Copy of kpmg_open_AI_named_entity_recognition_using_spacy_and_tensorflow.ipynb","provenance":[{"file_id":"19atKUGjjwwEYwAOK__pU4opjdmj8QDH4","timestamp":1591807122148}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ab21HXHA7j_W","colab_type":"text"},"source":["# Overview\n","\n","This Jupyter notebook demonstrates training and serving custom named entity recognition (NER) models, which are used to identify named entities such as locations, times, and people in text documents. NER is used in a number of business applications such as powering recommender systems, simplifying customer support, and optimizing internal search engines. \n","\n","The notebook is broken down into the following three sections:\n","   * NER packages: An overview of the language, license, and methodology of commercially available NER packages\n","   * NER with SpaCy : Code examples for training and serving a custom NER model in SpaCy\n","   * NER with Tensorflow : Code examples for creating, training, and serving a custom deep-learning NER model with Tensorflow\n","\n","# 1. Named Entity Recognition Research & Examples\n","\n","\n","\n","## Named entity recognition packages\n","\n","NER can be implemented with either statistical or rule-based methods, both of which require a large amount of labeled training data and are typically trained in a fully or semi-supervised manner. Statistical approaches to NER include Hidden Markov Models, Maximum Entropy, and Conditional Random Fields, as well as deep learning approaches with Recurrent Neural Networks, such as Seq2Seq. All of these processes involve sentence inputs and annotated sentence outputs. Many of these processes also involve additional feature engineering, providing as input summary statistics of the sentences.\n","\n","Many of the production-ready NER packages are written in Java and served as Docker containers, such as GATE, OpenNLP, and DBPedia spotlight. SpaCy is perhaps the most frequently used NER package in Python. \n","\n","\n","| Name | Language   | License | Method        |\n","|------|------------|--------|----------------|\n","| [GATE](https://github.com/GateNLP/gateplugin-Java) | Java       |   GPLv3     |  Hidden Markov |\n","|[OpenNLP](https://opennlp.apache.org)| Java      |     Apache 2.0   | Maximum Entropy / Rule-based |\n","|[DBPedia](https://opennlp.apache.org)| Java      |    Apache 2.0    | Rule-based |\n","|[SpaCy](https://spacy.io)| Python/Cython      |    MIT  | Convolutional NN |\n","\n","## NER Methods\n","\n","NER may be implemented with a variety of statistical and rule-based methods with varying amounts of feature engineering. All production-ready NER methods are at least semi-supervised, though unsupervised approaches are an emerging research topic.\n","\n","#### Supervised statistical\n","\n","Supervised statistical approaches to NER typically use either Hidden Markov Models (HMM), Maximum Entropy (ME), or Conditional Random Fields (CRF). OpenNLP's statistical NER relies on ME. GATE relies on HMM.\n","\n","Typical feature engineering approaches for NER include such approaches as orthography, n-grams, lexicons, suffixes and prefixes, unsupervised cluster features, and trigger words for named entities (such as river or lake). These features are generated algorithmically in a rule-based manner.\n","\n","    \n","#### Supervised rule-based\n","\n","OpenNLP contains rule based (as well as statistical) NER. The rule-based approach relies on a series of regular expression matches. The feature generation seems to be done with a beam search to determine the word context.\n","\n","DBPedia spotlight performs NER with substring matching using the Aho-Corasick algorithm. The approach only uses tokenization with no other feature engineering. The two-step approach first involves generating all possible candidate annotations that form known labels. This is rule-based in that it involves identifying nouns, prepositions, capitalized words, and known entities. This is based on OpenNLP under the hood. The second step selects the best candidates from the proposed candidates. Each candidate is scored based on annotation probability using a version of tf-idf with article links and anchor texts instead of documents and terms.\n","\n","\n","#### Supervised deep learning\n","\n","**[SpaCy](https://spacy.io),** which is one of the most popular productionized NER environments, **uses residual convolutional neural networks (CNN) and incremental parsing with Bloom embeddings for NER.** See [this](https://www.youtube.com/watch?v=sqDHBH9IjRU) Youtube explanation from the developers for more detail. To summarize the algorithm, 1D convolutional filters are applied over the input text to predict how the upcoming words may change the current entity tags. Upcoming words may either shift (change the entity), reduce (make the entity more granular), or output the entity. The input sequence is embedded with bloom embeddings, which model the characters, prefix, suffix, and part of speech of each word. Residual blocks are used for the CNNs, andn the filter sizes are chosen with beam search.\n","\n","Recurrent neural network (RNN) approaches to NER also exist, typically comprising long short term memory networks (LSTM) at either the word- or character-level, relying on word or character embeddings, respectively (e.g. word2vec, gloVe, FASTtext).\n","    \n","## NER Datasets\n","\n","Although there are a number of datasets for NER in other languages, here we will focus on English datasets. Many of the NER datasets are domain-specific (i.e. Twitter, biomedical, advertising, news). A few standard NER datasets are described below to show the range of domain applications of NER.\n","   * [i2b2](https://www.i2b2.org/NLP/DataSets/) - Medication, treatments, diseases, risk factors, and medications\n","   * [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) - English and german news articles annotated with location, organization, person, and miscellaneous\n","    \n","    \n","## NER Evaluation metrics\n","\n","NER is most commonly evaluated with precision, recall, and F1-score. F1-score can either be relaxed or strict, with the latter requiring the character offsets to match exactly. \n","    \n","# 2. Named entity recognition with SpaCy\n","\n","This section will focus on the Python package SpaCy for demonstrating named entity recognition. SpaCy is an open-source python library for NLP written in Python and Cython. It offers pre-trained models for multi-language NER, as well as allowing developers to train and deploy custom NER models on domain specific corpuses. SpaCy models are designed to be production-ready. \n","\n","SpaCy's pretrained models are trained on the [OntoNotes 5](https://catalog.ldc.upenn.edu/LDC2013T19) corpus, and support the identification of the [following entities](https://spacy.io/models/en): \n","\n","\n","|TYPE\t| DESCRIPTION\n","------------ | ------------\n","|PERSON\t| People, including fictional\n","|NORP\t|Nationalities or religious or political groups\n","|FAC\t|Buildings, airports, highways, bridges, etc\n","|ORG\t|Companies, agencies, institutions, etc\n","|GPE\t|Countries, cities, states\n","|LOC\t|Non-GPE locations, mountain ranges, bodies of water\n","|PRODUCT|\tObjects, vehicles, foods, etc. (Not services.)\n","|EVENT\t|Named hurricanes, battles, wars, sports events, etc\n","|WORK_OF_ART|\tTitles of books, songs, etc\n","|LAW\t|Named documents made into laws\n","|LANGUAGE|\tAny named language\n","|DATE\t|Absolute or relative dates or periods\n","|TIME\t|Times smaller than a day\n","|PERCENT|\tPercentage, including ”%“\n","|MONEY\t|Monetary values, including unit\n","|QUANTITY|\tMeasurements, as of weight or distance\n","|ORDINAL|\t“first”, “second”, etc\n","|CARDINAL|\tNumerals that do not fall under another type\n","\n","While these pretrained models are often sufficient for general applications, we will consider a domain-specific application of NER on the [MIT Movies corpus](https://groups.csail.mit.edu/sls/downloads/movie/), which contains 10,000 queries about various aspects of movies, with the following entity labels:\n","\n","| Type | Example |\n","------- | ------- |\n","| ACTOR | Matt Damon |\n","| YEAR | 1980s |\n","| TITLE | Pulp Fiction\n","| GENRE | science fiction\n","| DIRECTOR | George Lucas |\n","| SONG | Aerosmith |\n","| PLOT | Flying cars |\n","| REVIEW | must see |\n","| CHARACTER | Queen Elizabeth |\n","|RATING | PG-13 |\n","|RATINGS_AVERAGE | best rated |\n","| TRAILER | preview\n","\n","As these tables show, the pretrained SpaCy models would not be sufficient to identify entities to help answer a question such as \"did george clooney make a science fiction movie in the 1980s?\" While the pre-trained entities may identify the presence of `PERSON`, `DATE`, and `PRODUCT`, a custom model should be able to detect `ACTOR`, `GENRE`, and `DATE`. In the following sections, we will compare the results of applying a pre-trained and a custom-trained model to the MIT movies corpus."]},{"cell_type":"markdown","metadata":{"id":"JsRbGCwN7j_Y","colab_type":"text"},"source":["### Install and import required packages"]},{"cell_type":"code","metadata":{"id":"lU3aTiL57j_Z","colab_type":"code","colab":{}},"source":["# import sys\n","# !{sys.executable} -m pip install spacy # !{sys.executable} ensures package installation in conda env"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYkQWtkE7j_d","colab_type":"code","colab":{}},"source":["import spacy\n","import random\n","import time\n","import numpy as np\n","from spacy.util import minibatch, compounding"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QceRArC7j_g","colab_type":"text"},"source":["### Load and transform data"]},{"cell_type":"markdown","metadata":{"id":"cGgKdOsn7j_g","colab_type":"text"},"source":["Create the data directory if it doesn't exist"]},{"cell_type":"code","metadata":{"id":"OG4tLham7j_h","colab_type":"code","colab":{}},"source":["from os import path, mkdir\n","if not path.isdir(\"data/\"):\n","    mkdir(\"data/\")\n","if not path.isdir(\"models/\"):\n","    mkdir(\"models/\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbMTMM-B7j_l","colab_type":"text"},"source":["Download the test and training dataset from MIT's Computer Science and Aritficial Intelligence Laboratory (CSAIL)"]},{"cell_type":"code","metadata":{"id":"rv28pfoV7j_m","colab_type":"code","outputId":"c3684072-b575-4689-be00-e4773c00c6b8","executionInfo":{"status":"ok","timestamp":1591804512067,"user_tz":-60,"elapsed":9430,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["# !curl https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio -o data/test.txt\n","# !curl https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio -o data/train.txt\n","\n","\n","!curl https://groups.csail.mit.edu/sls/downloads/movie/trivia10k13test.bio  -o data/test.txt\n","!curl https://groups.csail.mit.edu/sls/downloads/movie/trivia10k13train.bio -o data/train.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  428k  100  428k    0     0   130k      0  0:00:03  0:00:03 --:--:--  130k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 1743k  100 1743k    0     0   649k      0  0:00:02  0:00:02 --:--:--  649k\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nVkhp_xh7j_p","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig1.png\" width=\"700\" align = \"left\"/>"]},{"cell_type":"markdown","metadata":{"id":"Y08QDiwo7j_q","colab_type":"text"},"source":["SpaCy requires training data to be in the format of `TRAIN_DATA = [(Sentence, {entities: [(start, end, label)]}, ...]`. The `load_data` function parses and transforms the input data into the required format for spaCy."]},{"cell_type":"code","metadata":{"id":"YEw6SG5Z7j_r","colab_type":"code","colab":{}},"source":["def load_data_spacy(file_path):\n","    ''' Converts data from:\n","    label \\t word \\n label \\t word \\n \\n label \\t word\n","    to: sentence, {entities : [(start, end, label), (stard, end, label)]}\n","    '''\n","    file = open(file_path, 'r')\n","    training_data, entities, sentence, unique_labels = [], [], [], []\n","    current_annotation = None\n","    end = 0 # initialize counter to keep track of start and end characters\n","    for line in file:\n","        line = line.strip(\"\\n\").split(\"\\t\")\n","        # lines with len > 1 are words\n","        if len(line) > 1:\n","            label = line[0][2:]     # the .txt is formatted: label \\t word, label[0:2] = label_type\n","            label_type = line[0][0] # beginning of annotations - \"B\", intermediate - \"I\"\n","            word = line[1]\n","            sentence.append(word)\n","            end += (len(word) + 1)  # length of the word + trailing space\n","            \n","            if label_type != 'I' and current_annotation:  # if at the end of an annotation\n","                entities.append((start, end - 2 - len(word), current_annotation))  # append the annotation\n","                current_annotation = None                 # reset the annotation\n","            if label_type == 'B':                         # if beginning new annotation\n","                start = end - len(word) - 1  # start annotation at beginning of word\n","                current_annotation = label   # append the word to the current annotation\n","            if label_type == 'I':            # if the annotation is multi-word\n","                current_annotation = label   # append the word\n","            \n","            if label != 'O' and label not in unique_labels:\n","                unique_labels.append(label)\n"," \n","        # lines with len == 1 are breaks between sentences\n","        if len(line) == 1: \n","            if current_annotation:\n","                entities.append((start, end - 1, current_annotation))\n","            sentence = \" \".join(sentence)\n","            training_data.append([sentence, {'entities' : entities}])\n","            # reset the counters and temporary lists\n","            end = 0            \n","            entities, sentence = [], []\n","            current_annotation = None\n","    file.close()\n","    return training_data, unique_labels            \n","            \n","TRAIN_DATA, LABELS = load_data_spacy(\"data/train.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-KkV3pH7j_u","colab_type":"text"},"source":["### Data overview"]},{"cell_type":"markdown","metadata":{"id":"-rpLoZiX7j_u","colab_type":"text"},"source":["Sample sentences from the training data, which contains queries about movie information"]},{"cell_type":"code","metadata":{"id":"0ZgRaMbW7j_v","colab_type":"code","outputId":"a82c16da-09a3-4960-fb10-aa56bfc35769","executionInfo":{"status":"ok","timestamp":1591804512528,"user_tz":-60,"elapsed":4190,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["[x[0] for x in TRAIN_DATA[1:10]]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['liza minnelli and joel gray won oscars for their roles in this 1972 movie that follows nightclub entertainers in berlin as the nazis come to power',\n"," 'what is that tom hanks and julia roberts movie about hanks who plays a down on his luck average guy who goes back to college and gets taught by roberts',\n"," 'what is the movie making fun of macgyver by re enacting scenes similar to his movies',\n"," 'i am thinking of an animated film based on a classic theodor geisel children s novel about a young boy s quest to save the trees',\n"," 'what 1981 feature film starring mel gibson takes place in a post apocalyptic world in australia',\n"," 'this steven speilberg supernatural story of a haunted house made many filmgoers afraid of clowns',\n"," 'in what 1997 movie is there a scene featuring muscians playing on the deck of a ship',\n"," 'what s the movie with julie andre where she sings and flies with an umbrella and dick van dyke',\n"," 'what is the movie where jbiebs does his concerts']"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"o_FC0aOV7j_z","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig2.png\" align = \"left\" width=\"600\"/>"]},{"cell_type":"markdown","metadata":{"id":"bRrG6R-S7j_0","colab_type":"text"},"source":["Sample labeled annotations for the training data"]},{"cell_type":"code","metadata":{"id":"_081BfQF7j_1","colab_type":"code","outputId":"4ccc7166-5179-41ad-ab26-04b6a9a715cb","executionInfo":{"status":"ok","timestamp":1591804512530,"user_tz":-60,"elapsed":2431,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["[x[1] for x in TRAIN_DATA[1:10]]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'entities': [(0, 13, 'Actor'),\n","   (18, 27, 'Actor'),\n","   (28, 38, 'Award'),\n","   (63, 67, 'Year'),\n","   (74, 146, 'Plot')]},\n"," {'entities': [(13, 22, 'Actor'), (27, 40, 'Actor'), (53, 151, 'Plot')]},\n"," {'entities': [(18, 84, 'Plot')]},\n"," {'entities': [(20, 28, 'Genre'), (34, 84, 'Origin'), (91, 128, 'Plot')]},\n"," {'entities': [(5, 9, 'Year'), (32, 42, 'Actor'), (43, 95, 'Plot')]},\n"," {'entities': [(5, 21, 'Director'), (22, 34, 'Genre'), (46, 59, 'Plot')]},\n"," {'entities': [(8, 12, 'Year')]},\n"," {'entities': [(22, 33, 'Actor'), (40, 76, 'Plot'), (81, 94, 'Actor')]},\n"," {'entities': [(24, 30, 'Actor'), (31, 48, 'Plot')]}]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"08AI6yGx7j_3","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig3.png\" align = \"left\" width=\"500\"/>"]},{"cell_type":"markdown","metadata":{"id":"H5U1AOy_7j_5","colab_type":"text"},"source":["### Test pre-trained NER Model\n","\n","First, download the pre-trained model with a subprocess call."]},{"cell_type":"code","metadata":{"id":"Ioiw21hB7j_5","colab_type":"code","colab":{}},"source":["#!{sys.executable} -m spacy download en"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S528tgcV7j_9","colab_type":"text"},"source":["The pretrained model fails to identify any genres, plots, actors, directors, characters, movie titles, or ratings present in the movie queries. Interestingly, it also fails to identify persons, works of art, and products! Clearly, the pretrained model does not fit this domain application, so we will train our own model from scratch.\n"]},{"cell_type":"code","metadata":{"id":"C18W3ZEA7j_-","colab_type":"code","outputId":"f5db585f-6eba-418b-c6a0-ac12a98b7921","executionInfo":{"status":"ok","timestamp":1591804519555,"user_tz":-60,"elapsed":1992,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":567}},"source":["from spacy import displacy\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","nlp = spacy.load('en')\n","TEST_DATA, _ = load_data_spacy(\"data/test.txt\")\n","\n","test_sentences = [x[0] for x in TEST_DATA[0:15]] # extract the sentences from [sentence, entity]\n","for x in test_sentences:\n","    doc = nlp(x)\n","    displacy.render(doc, jupyter = True, style = \"ent\")\n","warnings.filterwarnings(\"default\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i need that movie which involves aliens invading \n","<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    earth\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n","</mark>\n"," in a particular \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    united states\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," place in \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    california\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    soviet\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n","</mark>\n"," science fiction classic about a mysterious planet was later remade by \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    steven soderbergh\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," and \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    george clooney\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this \n","<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    american\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n","</mark>\n"," classic based on \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    margaret mitchell s\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," novel had \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    more than 50\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," speaking roles and \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2 400\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," extras in the film</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what is the movie starring \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    jessica biel\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," from \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2003\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," where a group of friends are stalked and hunted by a deformed killer with a chainsaw</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">in this movie \n","<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    ryan\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n","</mark>\n"," reynolds plays a superhero who must defend mankind from a a super powerful being who feeds on fear</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this classic \n","<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    world war ii\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n","</mark>\n"," era film stars \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    humphrey bogart\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," and \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    lauren bacall\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," and takes place in \n","<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    northern africa\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">originally a bestselling book by \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    kathryn stockett\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," this film gave octavia spencer an oscar for best supporting actress</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this movie documents a secret department of defense project that secretly returned to the moon with disastrous consequences</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    1933\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," movie starring the \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    marx\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," brothers finds \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    one\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," of the marx brothers as a soon to be president</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what movie depicts \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    two\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," men who have a weed business venture that is soon compromised by the kidnapping of the women they love</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this movie details the crippling effects of addiction on various characters released in \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2000\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," this film features \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    jennifer connelly\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," in a leading role one of the most memorable and depressing lines ass to ass what is the name of this film</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    1992\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    hong kong\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," action film directed by \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    john woo\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," starred \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    chow yun fat\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," as inspector \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    tequila yuen\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">name the film starting \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    steven seagal\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," about former seal now cook is the only person who can stop a gang of terrorists when they seize control of a \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    us navy\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," battleship</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what movie about the desert ends with a fatal motorcycle accident for its hero</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what controversial film did \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    mel gibson\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," direct about \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    the last days\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n"," in the life of jesus</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZsPi1UoV7kAC","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig4.png\" align = \"left\" width=\"500\"/>"]},{"cell_type":"markdown","metadata":{"id":"rVNiVUzt7kAC","colab_type":"text"},"source":["### Train and save custom NER model"]},{"cell_type":"code","metadata":{"id":"ZymJeSga8XmZ","colab_type":"code","outputId":"ac9a1db9-6c23-4295-b0ee-48d1fec11061","executionInfo":{"status":"ok","timestamp":1591804554054,"user_tz":-60,"elapsed":1717,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["LABELS"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Actor',\n"," '',\n"," 'Plot',\n"," 'Opinion',\n"," 'Award',\n"," 'Year',\n"," 'Genre',\n"," 'Origin',\n"," 'Director',\n"," 'Soundtrack',\n"," 'Relationship',\n"," 'Character_Name',\n"," 'Quote']"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"hbemGLASAr6Y","colab_type":"code","colab":{}},"source":["nlp = spacy.blank('en') \n","if 'ner' not in nlp.pipe_names:\n","    ner = nlp.create_pipe('ner')\n","    nlp.add_pipe(ner)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"agM-sTwbAs-o","colab_type":"code","colab":{}},"source":["# Add entity labels to the NER pipeline\n","for i in LABELS:\n","    ner.add_label(i)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz8BqlGHEbS2","colab_type":"code","colab":{}},"source":["# Disable other pipelines in SpaCy to only train NER\n","other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XAWF9p_Eb42","colab_type":"code","outputId":"458cfb2c-8893-4601-ede9-1d5a5fc9b2e6","executionInfo":{"status":"ok","timestamp":1591806643633,"user_tz":-60,"elapsed":819,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["other_pipes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"Nki3N4s3AnwM","colab_type":"code","colab":{}},"source":["# Disable other pipelines in SpaCy to only train NER\n","other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n","with nlp.disable_pipes(*other_pipes):\n","    nlp.vocab.vectors.name = 'spacy_model' # without this, spaCy throws an \"unnamed\" error\n","    optimizer = nlp.begin_training()\n","    for itr in range(iterations):\n","        random.shuffle(train_data) # shuffle the training data before each iteration\n","        losses = {}\n","        batches = minibatch(train_data, size = compounding(4., 32., 1.001))\n","        for batch in batches:\n","            texts, annotations = zip(*batch)\n","            nlp.update(texts, annotations, drop = dropout, sgd = optimizer, losses = losses)\n","        if itr % display_freq == 0:\n","            print(\"Iteration {} Loss: {}\".format(itr + 1, losses))\n","return nlp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kuy0dIL87kAD","colab_type":"code","outputId":"f8299736-408d-4f88-9d96-9f4c1a14f5e4","executionInfo":{"status":"ok","timestamp":1591795273312,"user_tz":-60,"elapsed":1330286,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["# A simple decorator to log function processing time\n","def timer(method):\n","    def timed(*args, **kw):\n","        ts = time.time()\n","        result = method(*args, **kw)\n","        te = time.time()\n","        print(\"Completed in {} seconds\".format(int(te - ts)))\n","        return result\n","    return timed\n"," \n","# Data must be of the form (sentence, {entities: [start, end, label]})\n","@timer\n","def train_spacy(train_data, labels, iterations, dropout = 0.2, display_freq = 1):\n","    ''' Train a spacy NER model, which can be queried against with test data\n","    \n","    train_data : training data in the format of (sentence, {entities: [(start, end, label)]})\n","    labels : a list of unique annotations\n","    iterations : number of training iterations\n","    dropout : dropout proportion for training\n","    display_freq : number of epochs between logging losses to console\n","    '''\n","    nlp = spacy.blank('en') \n","    if 'ner' not in nlp.pipe_names:\n","        ner = nlp.create_pipe('ner')\n","        nlp.add_pipe(ner)\n","    \n","    # Add entity labels to the NER pipeline\n","    for i in labels:\n","        ner.add_label(i)\n"," \n","    # Disable other pipelines in SpaCy to only train NER\n","    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n","    with nlp.disable_pipes(*other_pipes):\n","        nlp.vocab.vectors.name = 'spacy_model' # without this, spaCy throws an \"unnamed\" error\n","        optimizer = nlp.begin_training()\n","        for itr in range(iterations):\n","            random.shuffle(train_data) # shuffle the training data before each iteration\n","            losses = {}\n","            batches = minibatch(train_data, size = compounding(4., 32., 1.001))\n","            for batch in batches:\n","                texts, annotations = zip(*batch)\n","                nlp.update(           \n","                    texts,\n","                    annotations, \n","                    drop = dropout,   \n","                    sgd = optimizer,\n","                    losses = losses)\n","            if itr % display_freq == 0:\n","                print(\"Iteration {} Loss: {}\".format(itr + 1, losses))\n","    return nlp\n"," \n","# Train (and save) the NER model\n","ner = train_spacy(TRAIN_DATA, LABELS,20)\n","ner.to_disk(\"models/spacy_example\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Iteration 1 Loss: {'ner': 37373.37084499691}\n","Iteration 2 Loss: {'ner': 28880.680969356785}\n","Iteration 3 Loss: {'ner': 26651.210789997192}\n","Iteration 4 Loss: {'ner': 24905.397498326234}\n","Iteration 5 Loss: {'ner': 23892.378108589295}\n","Iteration 6 Loss: {'ner': 23019.988283243503}\n","Iteration 7 Loss: {'ner': 21624.82878853813}\n","Iteration 8 Loss: {'ner': 21481.742930171364}\n","Iteration 9 Loss: {'ner': 20747.828056389604}\n","Iteration 10 Loss: {'ner': 20082.10910411107}\n","Iteration 11 Loss: {'ner': 20293.158599207247}\n","Iteration 12 Loss: {'ner': 19301.694869200164}\n","Iteration 13 Loss: {'ner': 19004.503238173915}\n","Iteration 14 Loss: {'ner': 18377.36826540603}\n","Iteration 15 Loss: {'ner': 18206.56114951775}\n","Iteration 16 Loss: {'ner': 17448.410983085378}\n","Iteration 17 Loss: {'ner': 17696.028057155094}\n","Iteration 18 Loss: {'ner': 16880.626705643896}\n","Iteration 19 Loss: {'ner': 16639.939727148605}\n","Iteration 20 Loss: {'ner': 16601.57980386926}\n","Completed in 1329 seconds\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/spacy/language.py:900: ResourceWarning: unclosed file <_io.TextIOWrapper name='models/spacy_example/meta.json' mode='w' encoding='UTF-8'>\n","  srsly.json_dumps(self.meta)\n","/usr/local/lib/python3.6/dist-packages/spacy/util.py:645: ResourceWarning: unclosed file <_io.BufferedWriter name='models/spacy_example/vocab/vectors'>\n","  writer(path / key)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7vrLbwQT7kAG","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig5.png\" align = \"left\" width=\"400\"/>"]},{"cell_type":"markdown","metadata":{"id":"4JrOQqMk7kAH","colab_type":"text"},"source":["### Test model on new sentences"]},{"cell_type":"markdown","metadata":{"id":"OBIBb_Nk7kAH","colab_type":"text"},"source":["To test the model on new sentences, the `load_model` function is used to reload the trained model weights, and `load_data` is called to load and transform the test data. The spacy function `displacy` is used to visualize the predictions of the first 15 test sentences. As the results show, the architecture has learned good representations of the entities. However, there still exist a few errors. While some of these may be mitigated with increased training time (the loss was still decreasing rapidly after 5 iterations), others may require additional pre-processing, such as fixing spelling mistakes."]},{"cell_type":"code","metadata":{"id":"TvCm43Lv7kAI","colab_type":"code","outputId":"88815be0-ee62-40dd-b242-1fca3d235c17","executionInfo":{"status":"ok","timestamp":1591793919052,"user_tz":-60,"elapsed":1621,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":654}},"source":["from spacy import displacy\n","\n","def load_model(model_path):\n","    ''' Loads a pre-trained model for prediction on new test sentences\n","    \n","    model_path : directory of model saved by spacy.to_disk\n","    '''\n","    nlp = spacy.blank('en') \n","    if 'ner' not in nlp.pipe_names:\n","        ner = nlp.create_pipe('ner')\n","        nlp.add_pipe(ner)\n","    ner = nlp.from_disk(model_path)\n","    return ner\n","\n","ner = load_model(\"models/spacy_example\")\n","\n","TEST_DATA, _ = load_data_spacy(\"data/test.txt\")\n","\n","test_sentences = [x[0] for x in TEST_DATA[0:15]] # extract the sentences from [sentence, entity]\n","for x in test_sentences:\n","    doc = ner(x)\n","    displacy.render(doc, jupyter = True, style = \"ent\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i need that movie which involves \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    aliens invading earth in a particular united states place in california\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Plot</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what soviet \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    science fiction\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Genre</span>\n","</mark>\n"," classic about \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    a mysterious planet was later\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Plot</span>\n","</mark>\n"," remade by \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    steven soderbergh\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Director</span>\n","</mark>\n"," and \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    george clooney\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    american classic\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Genre</span>\n","</mark>\n"," \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    based on margaret mitchell s novel had more than 50 speaking roles\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Origin</span>\n","</mark>\n"," and 2 400 extras in the film</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what is the movie starring \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    jessica biel\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," from 2003 where \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    a group of friends are stalked and hunted by a deformed killer with a chainsaw\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Plot</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">in this movie \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    ryan reynolds\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," plays \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    a superhero who must defend mankind from a a super powerful being who feeds on fear\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Plot</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    classic\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Opinion</span>\n","</mark>\n"," \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    world war ii\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Genre</span>\n","</mark>\n"," era film stars \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    humphrey bogart\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," and \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    lauren bacall\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," and takes place in northern africa</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">originally a bestselling book by kathryn stockett this film gave octavia spencer an \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    oscar for best supporting actress\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Award</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n","  \"__main__\", mod_spec)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this movie documents a secret department of defense project that secretly returned to the moon with disastrous consequences</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    1933\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Year</span>\n","</mark>\n"," movie starring the \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    marx brothers\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," finds one of the marx brothers as a soon to be president</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what movie depicts \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    two men who have a weed business venture that is soon compromised by the kidnapping of the women they love\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Plot</span>\n","</mark>\n","</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">this movie details the crippling effects of addiction on various characters released in \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    2000\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Year</span>\n","</mark>\n"," this film features \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    jennifer connelly\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," in a leading role one of the most memorable and depressing lines ass to ass what is the name of this film</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    1992\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Year</span>\n","</mark>\n"," \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    hong kong action\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Genre</span>\n","</mark>\n"," film directed by \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    john woo\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Director</span>\n","</mark>\n"," starred \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    chow yun fat\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," as inspector tequila yuen</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">name the film starting \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    steven seagal\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," about former seal now cook is the only person who can stop a gang of terrorists when they seize control of a us navy battleship</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n","  \"__main__\", mod_spec)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what movie about the desert ends with a fatal motorcycle accident for its hero</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    controversial\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Genre</span>\n","</mark>\n"," film did \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    mel gibson\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Actor</span>\n","</mark>\n"," direct about the last days in the life of jesus</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"rJAoJldf7kAK","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig6.png\" align = \"left\" width=\"500\"/>"]},{"cell_type":"markdown","metadata":{"id":"2lv9x_mm7kAL","colab_type":"text"},"source":["### Evaluation Metrics\n","\n","Model performance is assessed on the entirety of the test dataset (2,443 sentences) based on the following metrics and their definitions.\n","\n","   * Precision: true positives / (true positives + false positives)\n","   * Recall: true positives / (true positives + false negatives)\n","   * F1-score: harmonic average of precision and recall"]},{"cell_type":"code","metadata":{"id":"NTEaGUgm7kAL","colab_type":"code","colab":{}},"source":["def calc_precision(pred, true):        \n","    precision = len([x for x in pred if x in true]) / (len(pred) + 1e-20) # true positives / total pred\n","    return precision\n","\n","def calc_recall(pred, true):\n","    recall = len([x for x in true if x in pred]) / (len(true) + 1e-20)    # true positives / total test\n","    return recall\n","\n","def calc_f1(precision, recall):\n","    f1 = 2 * ((precision * recall) / (precision + recall + 1e-20))\n","    return f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xn3JeY_p7kAP","colab_type":"code","outputId":"81fe66c6-4f4d-47d1-ad49-6b5912160e01","executionInfo":{"status":"ok","timestamp":1591795308924,"user_tz":-60,"elapsed":7391,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["from itertools import chain\n","\n","# run the predictions on each sentence in the test dataset, and return the spacy object\n","preds = [ner(x[0]) for x in TEST_DATA]\n","\n","precisions, recalls, f1s = [], [], [] \n","\n","# iterate over predictions and test data and calculate precision, recall, and F1-score\n","for pred, true in zip(preds, TEST_DATA): \n","    true = [x[2] for x in list(chain.from_iterable(true[1].values()))] # x[2] = annotation, true[1] = (start, end, annot)\n","    pred = [i.label_ for i in pred.ents] # i.label_ = annotation label, pred.ents = list of annotations\n","    precision = calc_precision(true, pred)\n","    precisions.append(precision)\n","    recall = calc_recall(true, pred)\n","    recalls.append(recall)\n","    f1s.append(calc_f1(precision, recall))\n","    \n","print(\"Precision: {} \\nRecall: {} \\nF1-score: {}\".format(np.around(np.mean(precisions), 3),\n","                                                         np.around(np.mean(recalls), 3),\n","                                                         np.around(np.mean(f1s), 3)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Precision: 0.833 \n","Recall: 0.888 \n","F1-score: 0.846\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"scrolled":true,"id":"FTvl_uPl7kAT","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig7.png\" align = \"left\" width=\"200\"/>"]},{"cell_type":"markdown","metadata":{"id":"xzGh6xCU7kAU","colab_type":"text"},"source":["# 3. Named entity recognition with Tensorflow\n","\n","This section focuses on developing, training, and serving a custom NER architecture with Tensorflow 1.9.0. We will implement an LSTM-CRF model as described in [Huang, Xu, and Yu, 2015](https://arxiv.org/pdf/1508.01991.pdf).\n","\n","This approach can be broken down into its constituent parts as follows:\n","   * Embedding: Generating a dense vector representation of words\n","   * LSTM: Incorporating past and future features to generate a representation of each time step\n","   * CRF: Make use of neighboring information to predict current tags. The CRF approach has been shown to provide higher accuracy than maximum entropy models because CRF considers the entire sentence rather than relying on beam search to find optimal context sizes. \n"]},{"cell_type":"code","metadata":{"id":"JyZubZoXCFh4","colab_type":"code","outputId":"d1da902e-5651-4096-d6ae-04689095fc30","executionInfo":{"status":"ok","timestamp":1591741765507,"user_tz":-60,"elapsed":2397,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["%tensorflow_version 1.x\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n","  return f(*args, **kwds)\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py:5747: ResourceWarning: unclosed file <_io.TextIOWrapper name='/root/.keras/keras.json' mode='r' encoding='UTF-8'>\n","  _config = json.load(open(_config_path))\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n"],"name":"stderr"},{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUHKdvrO7kAU","colab_type":"code","colab":{}},"source":["from functools import partial\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","import pickle\n","\n","params = {\n","    'dim' : 300,            # dimension of embeddings\n","    'maximum_steps' : 1000, # number of training steps        \n","    'lstm_size' : 150,      # dimension of LSTM\n","    'batch_size' : 25,      # batch size\n","    'max_words' : 20000,    # maximum number of words to embed\n","    'padding_size' : 20,    # maximum sentence size\n","    'num_classes' : 14,     # number of unique classes\n","    'save_dir' : 'models/' # directory to save hash tables, model weights, etc.\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bGTO65nX7kAX","colab_type":"text"},"source":["The first step in implementing a tensorflow named entity recognition architecture is to specify the data loading and transformation process. The words and labels need to be transformed to an integer vector format that tensorflow can process. Tokenization is used to do this, where unique words and labels are mapped to integers and the mapping is stored in a hashtable for back-conversion. \n","\n","For this process to work, however, we have to see all of the training data all at once to prevent overlapping hashes. This means that this tokenization process needs to happen separately from the training process. The `make_tokenizer` function takes in the training data and labels and returns two dictionaries, `word_index`, and `labels_index`. The former specifies integer mappings for the words, and the latter specifies integer mappings for the labels. "]},{"cell_type":"code","metadata":{"id":"z4wRMrwn7kAX","colab_type":"code","outputId":"c5be9b8a-c75b-4551-e714-fb4ca7b88938","executionInfo":{"status":"ok","timestamp":1591741918621,"user_tz":-60,"elapsed":1660,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def save_obj(directory, obj, name):\n","    '''Helper function using pickle to save and load objects'''\n","    with open(directory + name + '.pkl', 'wb+') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(directory, name):\n","    '''Helper function using pickle to save and load objects'''\n","    with open(directory + name + \".pkl\", \"rb\") as f:\n","        return pickle.load(f)\n","    \n","def load_data(file = \"data/train.txt\"):\n","    '''Helper function to load and transform inputs and labels\n","    included as a separate function due to NER-specific evaluation needs:\n","        tensorflow does not have multi-class precision/accuracy as a metric\n","        so data_y is needed to manually calculate evaluations'''\n","    file = open(file, 'r')\n","    sentence, labels = [], []\n","    data_x, data_y = [], []\n","    for line in file:\n","        line = line.strip(\"\\n\").split(\"\\t\")\n","        \n","        # lines with len > 1 are words\n","        if len(line) > 1:\n","            sentence.append(line[1])\n","            labels.append(line[0][2:]) if len(line[0]) > 1 else labels.append(line[0])\n","        \n","        # lins with len == 1 are sentence breaks\n","        if len(line) == 1: \n","            data_x.append(' '.join(sentence))\n","            data_y.append(labels)\n","            sentence, labels = [], []\n","    return data_x, data_y\n","\n","def make_tokenizer(file = \"data/train.txt\", params = params):\n","    ''' In order for one hot encoding of words and labels to work, \n","    every word and label has to be seen at least once to make a hashing table.\n","    This function outputs hash tables for the words and the labels\n","    that can be used to one-hot-encode them in the generator\n","    '''\n","    # Load parameters and data\n","    max_words = params['max_words']\n","    padding_size = params['padding_size']\n","    save_dir = params['save_dir']\n","    data_x, data_y = load_data(file)\n","            \n","    # Use the Keras tokenizer API to generate hashing table for data_x\n","    tokenizer = Tokenizer(num_words = max_words)\n","    \n","    tokenizer.fit_on_texts(data_x)\n","    word_index = tokenizer.word_index\n","    \n","    # Flatten data_y and create hashing table using set logic\n","    data_y_flattened = [item for sublist in data_y for item in sublist]\n","    data_x_flattened = [item for sublist in data_x for item in sublist]\n","    \n","    labels_index = dict([(y, x + 1) for x, y in enumerate(sorted(set(data_y_flattened)))])\n","    labels = []\n","    for item in data_y:\n","        labels.append([labels_index.get(i) for i in item])\n","    labels_lookup = {v : k for k, v in labels_index.items()} # reverse dictionary for lookup\n","    # save hash tables to disk for model serving\n","    for item, name in zip([word_index, labels_index, labels_lookup],\n","                          [\"word_index\", \"labels_index\", \"labels_lookup\"]):\n","        save_obj(save_dir, item, name)\n","    return word_index, labels_index, labels_lookup\n","\n","word_index, labels_index, labels_lookup = make_tokenizer()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: ResourceWarning: unclosed file <_io.TextIOWrapper name='data/train.txt' mode='r' encoding='UTF-8'>\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"s9dBu5xz7kAa","colab_type":"code","outputId":"3ae6c252-fa2c-430e-b29a-80dd842314d8","executionInfo":{"status":"ok","timestamp":1591741918622,"user_tz":-60,"elapsed":1026,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["labels_index"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Actor': 1,\n"," 'Award': 2,\n"," 'Character_Name': 3,\n"," 'Director': 4,\n"," 'Genre': 5,\n"," 'O': 6,\n"," 'Opinion': 7,\n"," 'Origin': 8,\n"," 'Plot': 9,\n"," 'Quote': 10,\n"," 'Relationship': 11,\n"," 'Soundtrack': 12,\n"," 'Year': 13}"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"M90HdW6f7kAc","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig8.png\" align = \"left\" width=\"200\"/>"]},{"cell_type":"markdown","metadata":{"id":"DUSW-mL57kAd","colab_type":"text"},"source":["Next, we create a generator to serve as input to the tensorflow DataSet API. The `generate_batches` function takes training data in BIO format and yields batches as input to the model function. The DataSet API requires two inputs - features and labels. For a recurrent neural network, we also need to specify sequence lengths to mask variable length sequences. This length is returned as a tuple in the features, as `(batch_x, lengths)`."]},{"cell_type":"code","metadata":{"id":"V1WzhGwq7kAd","colab_type":"code","colab":{}},"source":["def generate_batches(file = \"data/train.txt\", params = params, train = True):\n","    ''' Generate minibatch with dimensions:\n","    batch_x : (batch_size, max_len)\n","    lengths : (batch_size,)\n","    batch_y : (batch_size, num_classes)\n","    \n","    file : path to .txt containing training data in BIO format\n","    '''\n","    \n","    batch_size = params['batch_size']\n","    max_len = params['padding_size']\n","    save_dir = params['save_dir']\n","    \n","    # load hash tables for tokenization\n","    for item, name in zip([word_index, labels_index, labels_lookup],\n","                          [\"word_index\", \"labels_index\", \"labels_lookup\"]):\n","        item = load_obj(save_dir, name)\n","    \n","    while True:\n","        with open(file, 'r') as f:\n","            batch_x, lengths, batch_y = [], [], []\n","            words, labels = [], []\n","            for line in f:\n","                line = line.strip(\"\\n\").split(\"\\t\")\n","                # lines with len > 1 are words\n","                if len(line) > 1:\n","                    labels.append(line[0][2:]) if len(line[0]) > 1 else labels.append(line[0])\n","                    words.append(line[1])\n","\n","                # lines with len == 1 are breaks between sentences\n","                if len(line) == 1: \n","                    words = [word_index.get(x) if x in word_index.keys() else 0 for x in words]\n","                    labels = [labels_index.get(y) for y in labels]\n","                    batch_x.append(words)\n","                    batch_y.append(labels)\n","                    lengths.append(min(len(words), max_len))\n","                    words, labels = [], []\n","\n","                if len(batch_x) == batch_size:\n","                    batch_x = pad_sequences(batch_x, maxlen = max_len, value = 0, padding = \"post\")\n","                    batch_y = pad_sequences(batch_y, maxlen = max_len, value = 0, padding = \"post\")\n","                    yield (batch_x, lengths), batch_y \n","                    batch_x, lengths, batch_y = [], [], []\n","            if train == False:\n","                break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YwONV36w7kAh","colab_type":"text"},"source":["The estimator API requires an input function and a model function. The `input_fn` maps the `generate_batches` generator to a tensorflow Dataset."]},{"cell_type":"code","metadata":{"id":"27Z_ZymU7kAh","colab_type":"code","colab":{}},"source":["# For model training, we need an input function that will feed a tf.Dataset\n","def input_fn(file, params = None, train = True):\n","    params = params if params is not None else {}\n","    shapes = (([None, None], [None]), [None, None]) # batch_x, lengths, batch_y shapes\n","    types = ((tf.int32, tf.int32), tf.int32)        # batch_x, lengths, batch_y data types\n","    \n","    generator = partial(generate_batches, file, train = train)\n","    dataset = tf.data.Dataset.from_generator(generator, types, shapes)\n","    return dataset\n","\n","# For model serving, we need a serving function that will feed tf.placeholders\n","def serving_input_fn():\n","    words = tf.placeholder(dtype=tf.int32, shape=[None, None], name='words')\n","    length = tf.placeholder(dtype=tf.int32, shape=[None], name='length')\n","    receiver_tensors = {'words': words, 'length': length}\n","    features = {'words': words, 'length': length}\n","    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kg9oCzhP7kAk","colab_type":"text"},"source":["The `model_fn` unpacks features and labels to create the specified model architecture, which is an LSTM-CRF."]},{"cell_type":"code","metadata":{"id":"0Mm71hUU7kAl","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params = params):\n","    # import the data and unpack the features\n","    # serving input_fn returns a dict, convert to multivalue obj\n","    if isinstance(features, dict):\n","        features = features['words'], features['length']\n","    \n","    words, length = features\n","    \n","    # Embedding\n","    embedding = tf.Variable(tf.random.normal([params['max_words'], params['dim']]))\n","    embedding_lookup_for_x = tf.nn.embedding_lookup(embedding, words)\n","    \n","    # LSTM\n","    lstm_cell_fw = tf.nn.rnn_cell.BasicLSTMCell(params['lstm_size'], state_is_tuple = True)\n","    lstm_cell_bw = tf.nn.rnn_cell.BasicLSTMCell(params['lstm_size'], state_is_tuple = True)\n","    states, final_state = tf.nn.bidirectional_dynamic_rnn(\n","                                        cell_fw = lstm_cell_fw, \n","                                        cell_bw = lstm_cell_bw,\n","                                        inputs = embedding_lookup_for_x, \n","                                        dtype = tf.float32,\n","                                        time_major = False,\n","                                        sequence_length = length)\n","    lstm_out = tf.concat([states[0], states[1]], axis = 2)\n","        \n","    # Conditional random fields\n","    logits = tf.layers.dense(lstm_out, params['num_classes'])\n","    crf_params = tf.get_variable(\"crf\", [params['num_classes'], params['num_classes']],\n","                                 dtype=tf.float32)\n","    pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, length)\n","    training = (mode == tf.estimator.ModeKeys.TRAIN)\n","    \n","    # Prediction\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        predictions = { \n","            'pred_ids': pred_ids,\n","            'tags': words,\n","            'length' : length,\n","        }\n","        export_outputs = {\n","          'prediction': tf.estimator.export.PredictOutput(predictions)\n","        }\n","        \n","        return tf.estimator.EstimatorSpec(mode, predictions=predictions,\n","                                          export_outputs=export_outputs)\n","    \n","    # Loss functions and optimizers\n","    log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n","        logits, labels, length, crf_params)\n","    \n","    loss = tf.reduce_mean(-log_likelihood)\n","    train_op = tf.train.AdamOptimizer().minimize(\n","        loss, global_step = tf.train.get_or_create_global_step())\n","        \n","    # Training\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode = mode,\n","                                           loss = loss,\n","                                           train_op = train_op)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZ1tHLM27kAp","colab_type":"text"},"source":["The Estimator API requires separate \"Spec\" objects, through `tf.estimator.TrainSpec` and `EvalSpec` for training and evaluation configuration. We use `functools.partial` to modify the input to the `input_fn` to create separate training and evaluation inputs, and then create separate `Spec` objects for training and evaluation."]},{"cell_type":"code","metadata":{"id":"tY195gcZ7kAp","colab_type":"code","outputId":"f5a0eba4-ae1c-4c58-de66-c9a4e62e619d","executionInfo":{"status":"ok","timestamp":1591741928594,"user_tz":-60,"elapsed":745,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["# Spin up the estimator\n","config = tf.estimator.RunConfig()\n","estimator = tf.estimator.Estimator(model_fn, 'models/model', config, params)\n","\n","# Create train spec\n","train_input_fn = partial(input_fn, \"data/train.txt\", params = params)\n","train_spec = tf.estimator.TrainSpec(train_input_fn)\n","\n","# Create evaluation spec\n","eval_input_fn = partial(input_fn, \"data/test.txt\", params = params, train = False)\n","eval_spec = tf.estimator.EvalSpec(eval_input_fn)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'models/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdbfd9d5b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Elhqngyk7kAu","colab_type":"text"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"DtHlf0UT7kAu","colab_type":"code","outputId":"b37ccfb7-9428-4847-9fa4-308c30855924","executionInfo":{"status":"ok","timestamp":1591742094826,"user_tz":-60,"elapsed":163274,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["ts = time.time()\n","estimator.train(input_fn = train_input_fn, max_steps = 1000)\n","te = time.time()\n","print(\"Completed in {} seconds\".format(int(te - ts)))\n","estimator.export_savedmodel('models/saved_model/', serving_input_fn)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:From <ipython-input-25-d037367568d7>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-25-d037367568d7>:22: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From <ipython-input-25-d037367568d7>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n","  return f(*args, **kwds)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into models/model/model.ckpt.\n","INFO:tensorflow:loss = 45.222374, step = 1\n","INFO:tensorflow:global_step/sec: 6.46426\n","INFO:tensorflow:loss = 12.744277, step = 101 (15.472 sec)\n","INFO:tensorflow:global_step/sec: 6.61489\n","INFO:tensorflow:loss = 8.408835, step = 201 (15.117 sec)\n","INFO:tensorflow:global_step/sec: 4.89604\n","INFO:tensorflow:loss = 8.652375, step = 301 (20.424 sec)\n","INFO:tensorflow:global_step/sec: 6.59557\n","INFO:tensorflow:loss = 6.398875, step = 401 (15.163 sec)\n","INFO:tensorflow:global_step/sec: 6.68781\n","INFO:tensorflow:loss = 4.931961, step = 501 (14.954 sec)\n","INFO:tensorflow:global_step/sec: 6.67365\n","INFO:tensorflow:loss = 3.557494, step = 601 (14.983 sec)\n","INFO:tensorflow:global_step/sec: 6.7414\n","INFO:tensorflow:loss = 4.292959, step = 701 (14.835 sec)\n","INFO:tensorflow:global_step/sec: 6.74451\n","INFO:tensorflow:loss = 4.6295815, step = 801 (14.827 sec)\n","INFO:tensorflow:global_step/sec: 6.76432\n","INFO:tensorflow:loss = 1.7395911, step = 901 (14.781 sec)\n","INFO:tensorflow:Saving checkpoints for 1000 into models/model/model.ckpt.\n","INFO:tensorflow:Loss for final step: 2.621218.\n","Completed in 161 seconds\n","WARNING:tensorflow:From <ipython-input-27-cda9b03471e7>:5: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function has been renamed, use `export_saved_model` instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","INFO:tensorflow:Restoring parameters from models/model/model.ckpt-1000\n","INFO:tensorflow:Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","INFO:tensorflow:SavedModel written to: models/saved_model/temp-b'1591742094'/saved_model.pb\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["b'models/saved_model/1591742094'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"grYAL_oz7kAx","colab_type":"text"},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{"id":"p-nnrRJs7kAx","colab_type":"text"},"source":["Although one might normally use `if mode == tf.estimator.ModeKeys.EVAL` in the `model_fn` to specify evaluation metrics with `tf.metrics`, NER requires multi-class precision, recall, and F1-score which are not available in `tf.metrics`. Instead, we load the true test labels and calculate precision, recall, and F1-score based upon the model predictions for each sentence at the entity-level (discarding non-entity words)."]},{"cell_type":"code","metadata":{"id":"6Ms4AeDE7kAx","colab_type":"code","outputId":"5f1594c5-2848-438a-b1cf-290e47884edd","executionInfo":{"status":"ok","timestamp":1591742116587,"user_tz":-60,"elapsed":4668,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["# Generate predictions\n","predictions = estimator.predict(eval_input_fn)\n","\n","# Load hash tables and true labels\n","labels_index = load_obj(params['save_dir'], \"labels_index\")\n","_, true = load_data(\"data/test.txt\")\n","\n","# Specify which label_index is non-entity\n","dummy_label = labels_index.get(\"O\") \n","\n","# Convert [[string, string], [string, string] ...] to [[int, int], [int, int]]\n","# with hashing table for label indexes\n","labels = []\n","for row in true:\n","    labels.append([labels_index.get(y) for y in row])\n","    \n","# Loop through preds, labels and calculate metrics\n","precisions, recalls, f1s = [], [], []\n","for pred, true in zip(predictions, labels):\n","    pred = pred['pred_ids'][:pred['length']] # undo pad_sequences\n","    pred = [x for x in pred if x != dummy_label] # remove preds that aren't entities\n","    true = np.asarray([x for x in true if x != dummy_label])\n","    recall = calc_recall(true, pred)\n","    recalls.append(recall)\n","    precision = calc_precision(true, pred)\n","    precisions.append(precision)\n","    f1s.append(calc_f1(precision, recall))\n","    \n","print(\"Precision: {} \\nRecall: {} \\nF1-score: {}\".format(np.around(np.mean(precisions), 3),\n","                                                         np.around(np.mean(recalls), 3),\n","                                                         np.around(np.mean(f1s), 3)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: ResourceWarning: unclosed file <_io.TextIOWrapper name='data/test.txt' mode='r' encoding='UTF-8'>\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from models/model/model.ckpt-1000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","Precision: 0.884 \n","Recall: 0.917 \n","F1-score: 0.886\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bvOJ8nkm7kA0","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig9.png\" align = \"left\" width=\"200\"/>"]},{"cell_type":"markdown","metadata":{"id":"bjmk_Ht37kA0","colab_type":"text"},"source":["### Serving model for on-the-fly predictions\n"]},{"cell_type":"code","metadata":{"id":"JULMJOmI7kA1","colab_type":"code","outputId":"ea1b78db-8e41-4862-825a-0999950c832e","executionInfo":{"status":"ok","timestamp":1591722678407,"user_tz":-60,"elapsed":1015,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAoLssH_ocMhCYfylkpZTzFkFfr2bQPfbNMxj1=s64","userId":"05807629945880251806"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"source":["from pathlib import Path\n","from tensorflow.contrib import predictor\n","\n","LINE = 'did george clooney make a science fiction movie in the 1980s'\n","\n","\n","def predict(line, export_dir = 'models/saved_model/', params = params):\n","    # Load hash tables\n","    word_index = load_obj(params['save_dir'], \"word_index\")\n","    labels_lookup = load_obj(params['save_dir'], \"labels_lookup\")\n","    \n","    # Identify and load model weights\n","    subdirs = [x for x in Path(export_dir).iterdir()\n","                   if x.is_dir() and 'temp' not in str(x)]\n","    latest_model = str(sorted(subdirs)[-1])\n","    predict_fn = predictor.from_saved_model(latest_model)\n","                \n","    # Preprocess sentence input\n","    line = line.strip().split()\n","    vector = [word_index.get(x) if x in word_index.keys() else 0 for x in line] # tokenize\n","    vector[len(vector):20] = [0] * (20 - len(vector)) # pad prediction\n","        \n","    # Calculate precision and transform for display\n","    predictions = predict_fn({'words': [vector], 'length': [len(line)]})\n","    tags = predictions.get('tags')\n","    preds = predictions.get('pred_ids')\n","    for tag, pred in zip(tags, preds):\n","        tag = [word for word in tag if word != 0] # unpad\n","        pred = pred[:len(tag)]\n","        pred = [labels_lookup.get(num) for num in pred] #untokenize\n","        print(line, \"\\n\", pred)\n","    \n","predict(LINE)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n","INFO:tensorflow:Restoring parameters from models/saved_model/1591722400/variables/variables\n","['did', 'george', 'clooney', 'make', 'a', 'science', 'fiction', 'movie', 'in', 'the', '1980s'] \n"," ['O', 'ACTOR', 'ACTOR', 'O', 'O', 'GENRE', 'GENRE', 'O', 'O', 'O', 'YEAR']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6cm8ptjy7kA4","colab_type":"text"},"source":["<img src=\"https://storage.googleapis.com/kf-pipeline-contrib-public/release-0.1.3/kfp-components/notebooks/entity_extraction/assets/fig10.png\" align = \"left\" width=\"800\"/>"]},{"cell_type":"markdown","metadata":{"id":"CAvPscJr7kA5","colab_type":"text"},"source":["## Conclusion\n","\n","This notebook shows two end-to-end approaches of training and serving custom NER models including loading and transforming data, creating an NER pipeline, and calculating performance metrics. The custom architecture developed in Tensorflow was competitive with out-of-the-box algorithms while being an order of magnitude faster to train and being able to use the powerful high level APIs in tensorflow like Dataset and Estimator for scalable serving.\n","\n","Both approaches perform well on diverse queries about movies with spelling mistakes and complicated query structures. NER pipelines like the ones presented in this notebook can be integrated into recommender systems, search engines, NLP feature engineering, and customer support / chatbots, among many other business applications."]}]}