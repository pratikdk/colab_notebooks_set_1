{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"v7_clinical_text_analysis.ipynb","provenance":[{"file_id":"1Pj2sP1atj_tfO9q1LnGBTgsoX2Xpv2qe","timestamp":1595744754895}],"collapsed_sections":["CFUV01CUNnNK"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ab8e01838c5048b3a1345f01118fa230":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3864f8a2dd2541debe0acab6fe13a0c3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_385e02c062824a6f8fc1a9fd3d0adc90","IPY_MODEL_b65c73d5edc64a87a7e0d8342693c1ee"]}},"3864f8a2dd2541debe0acab6fe13a0c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"385e02c062824a6f8fc1a9fd3d0adc90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6eaa28b45bf04938bee2e59ed393cfe9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae3de1e34b584377bb9f692b7ec83d0e"}},"b65c73d5edc64a87a7e0d8342693c1ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bdb815658fd4b3595ab3a42ec405f5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 587kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24a1f6a407b24c819cbff4b01e631cf2"}},"6eaa28b45bf04938bee2e59ed393cfe9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae3de1e34b584377bb9f692b7ec83d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bdb815658fd4b3595ab3a42ec405f5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24a1f6a407b24c819cbff4b01e631cf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mroThyXkepR_","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"WNeAPbOpKlF_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595876044231,"user_tz":-330,"elapsed":3021,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"34b41c35-0371-4491-9406-c376c7bfce02"},"source":["import os\n","import sys\n","import shutil \n","from distutils.dir_util import copy_tree # Shutil doesn't preserve meta\n","import random\n","import time\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import HTML\n","%matplotlib inline"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iYiAr7zkinQq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876045870,"user_tz":-330,"elapsed":4631,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"bc5f7284-fc17-4dbf-de9a-869736b85822"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PZhjFMm9dt6p","colab_type":"code","colab":{}},"source":["plt.style.use(\"ggplot\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4LJq67hSvra","colab_type":"code","colab":{}},"source":["pd.set_option('display.max_columns', None)  \n","pd.set_option('display.expand_frame_repr', False)\n","pd.set_option('max_colwidth', None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kFcJEPxTXQLk","colab_type":"text"},"source":["## Load Dataset"]},{"cell_type":"code","metadata":{"id":"Jy9TvlccK5na","colab_type":"code","colab":{}},"source":["if not os.path.isfile(\"LES_1m.zip\"):\n","  !mkdir -p data\n","  !wget -O 'LES_1m.zip' https://raw.githubusercontent.com/nirvana0311/ml_datasets/master/labeledEligibilitySample1000000.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzwwaCq_MsnD","colab_type":"code","colab":{}},"source":["large_data = pd.read_csv('LES_1m.zip', usecols=[1,2], names=['label','prescription'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ve1WX3UQRPLy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1595876048785,"user_tz":-330,"elapsed":7432,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"285d488f-e907-4c46-c0c6-8c66ff2f23e3"},"source":["large_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>prescription</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                                                                                                                                                                                                                                                                          prescription\n","0      0                                                                                                                                                                              study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri\n","1      0                                                                                                                                                                                                        study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular\n","2      0                                                                                                                                    study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement\n","3      0  study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen\n","4      0                                                                                                                                 study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Ep4VxxFzQg0e","colab_type":"code","colab":{}},"source":["small_data = large_data.iloc[:100, :] \n","small_data.to_csv('data/small_data.csv', index=False) # Select only first 100 rows"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHpQr93VOsG8","colab_type":"text"},"source":["## Data Filtering & Preprocessing"]},{"cell_type":"code","metadata":{"id":"N3CYFJaruBxC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1595876050691,"user_tz":-330,"elapsed":9288,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"6c37a7f3-4e19-40db-d82d-aca6a90f934c"},"source":["large_data['prescription'].apply(lambda x: len(x.split())).describe()\n","# Min token count is 4\n","# Max token count is 439"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    1000000.000000\n","mean          21.219562\n","std           11.540169\n","min            4.000000\n","25%           14.000000\n","50%           19.000000\n","75%           25.000000\n","max          439.000000\n","Name: prescription, dtype: float64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"FauWA8mu1ZZf","colab_type":"code","colab":{}},"source":["# Max length sequence threshold\n","# About 4 sequences cross the max_raw_seq_length threshold\n","max_raw_seq_length = 205"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xyx0wrILs0kA","colab_type":"code","colab":{}},"source":["# Truncating longer prescription sequences to 205 words, Max Sequence length observd in dataset contains 439 tokens\n","# Bert operates on 512 tokens (But for sequences with unseen vocab it might double the tokens, which can result in index errors[Limitation of BERT, Fixed length])\n","large_data['prescription'] = large_data['prescription'].str.split().str.slice(start=0, stop=max_raw_seq_length).str.join(\" \").str.strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DKx54svOsJM","colab_type":"code","colab":{}},"source":["lg_data = large_data.copy()\n","large_data = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VLnZ_VXsO5Er","colab":{}},"source":["lg_data[['intervention','condition']] = lg_data['prescription'].str.split('.', n=1, expand=True)\n","lg_data['intervention'] = lg_data['intervention'].str.strip()\n","lg_data['condition'] = lg_data['condition'].str.strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6cKNiKxCO5E3","colab":{}},"source":["lg_data['intervention'] = lg_data['intervention'].str.extract('(?<=are )(.*)', expand=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7wa94JJ-O5E8","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1595876069416,"user_tz":-330,"elapsed":27873,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"9f9fc2be-23d3-43ae-9788-1fdb959355d9"},"source":["lg_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>prescription</th>\n","      <th>intervention</th>\n","      <th>condition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri</td>\n","      <td>recombinant CD40-ligand</td>\n","      <td>melanoma skin diagnosis and no active cns metastases by ct scan or mri</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular</td>\n","      <td>Liposomal doxorubicin</td>\n","      <td>colorectal cancer diagnosis and cardiovascular</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement</td>\n","      <td>BI 836909</td>\n","      <td>multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen</td>\n","      <td>Immunoglobulins</td>\n","      <td>recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy</td>\n","      <td>Paclitaxel</td>\n","      <td>stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                                                                                                                                                                                                                                                                          prescription             intervention                                                                                                                                                                                                                                                   condition\n","0      0                                                                                                                                                                              study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri  recombinant CD40-ligand                                                                                                                                                                                      melanoma skin diagnosis and no active cns metastases by ct scan or mri\n","1      0                                                                                                                                                                                                        study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular    Liposomal doxorubicin                                                                                                                                                                                                              colorectal cancer diagnosis and cardiovascular\n","2      0                                                                                                                                    study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement                BI 836909                                                                                                                              multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement\n","3      0  study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen          Immunoglobulins  recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen\n","4      0                                                                                                                                 study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy               Paclitaxel                                                                                                                            stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"MJxUmRL3FR4S","colab_type":"text"},"source":["### Discarding [Missing, Incomplete, Bad] entries\n","\n"]},{"cell_type":"code","metadata":{"id":"92_bGv0iFbCP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1595876069975,"user_tz":-330,"elapsed":28398,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"cd03d3a9-19de-4217-9793-4be59440067e"},"source":["# Overview\n","bad_lg_data = lg_data[(lg_data.isnull().any(axis=1)) | (lg_data['condition'] == '')]\n","bad_lg_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>prescription</th>\n","      <th>intervention</th>\n","      <th>condition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>999923</th>\n","      <td>1</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999934</th>\n","      <td>1</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999939</th>\n","      <td>1</td>\n","      <td>study interventions are Antineoplastic Agents</td>\n","      <td>Antineoplastic Agents</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999950</th>\n","      <td>1</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999986</th>\n","      <td>1</td>\n","      <td>study interventions are INO-3106</td>\n","      <td>INO-3106</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41347 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["        label                                   prescription           intervention condition\n","5           0             study interventions are Antibodies             Antibodies      None\n","26          0             study interventions are Antibodies             Antibodies      None\n","45          0             study interventions are Antibodies             Antibodies      None\n","52          0             study interventions are Antibodies             Antibodies      None\n","73          0             study interventions are Antibodies             Antibodies      None\n","...       ...                                            ...                    ...       ...\n","999923      1             study interventions are Antibodies             Antibodies      None\n","999934      1             study interventions are Antibodies             Antibodies      None\n","999939      1  study interventions are Antineoplastic Agents  Antineoplastic Agents      None\n","999950      1             study interventions are Antibodies             Antibodies      None\n","999986      1               study interventions are INO-3106               INO-3106      None\n","\n","[41347 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"CN8jirkkJwqg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1595876069977,"user_tz":-330,"elapsed":28350,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"53fa6eb3-d81d-43ad-d4c5-9313a8f7bd86"},"source":["print(bad_lg_data.shape)\n","bad_lg_data.head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(41347, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>prescription</th>\n","      <th>intervention</th>\n","      <th>condition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>0</td>\n","      <td>study interventions are Antibodies</td>\n","      <td>Antibodies</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    label                        prescription intervention condition\n","5       0  study interventions are Antibodies   Antibodies      None\n","26      0  study interventions are Antibodies   Antibodies      None\n","45      0  study interventions are Antibodies   Antibodies      None\n","52      0  study interventions are Antibodies   Antibodies      None\n","73      0  study interventions are Antibodies   Antibodies      None"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"d8-4dJ8zJhg4","colab_type":"code","colab":{}},"source":["bad_counts_df = pd.DataFrame(bad_lg_data['intervention'].value_counts()).reset_index().reset_index()\n","bad_counts_df.columns = ['id', 'intervention', 'count']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Lz-oY2aKQu1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1595876069979,"user_tz":-330,"elapsed":28296,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"50c14b8a-efe6-4a63-e53a-4bed941e1d4c"},"source":["bad_counts_df.head(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>intervention</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antibodies</td>\n","      <td>34810</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Calcium</td>\n","      <td>2330</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Heparin</td>\n","      <td>253</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Estrogens</td>\n","      <td>230</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id intervention  count\n","0   0   Antibodies  34810\n","1   1      Calcium   2330\n","2   2      Heparin    253\n","3   3    Estrogens    230"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"xbhyTDQ0LBPZ","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(20, 6))\n","# ax = sns.barplot(x=\"id\", y=\"count\", data=bad_counts_df)\n","# ax.set_yscale(\"log\")\n","# for ind, label in enumerate(ax.get_xticklabels()):\n","#     if ind % 10 == 0:  # every 10th label is kept\n","#         label.set_visible(True)\n","#     else:\n","#         label.set_visible(False)\n","# plt.savefig('bad_dataFreq.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9zGsGQ3IZa1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"ok","timestamp":1595876069982,"user_tz":-330,"elapsed":28137,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"f97e80f5-6452-4afd-a2ca-60fc67dab509"},"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1FMwZtNxHJCTwPKuXKJ4ZsdSKUXpgIZCJ/preview\" width=\"1000\" height=\"300\"></iframe>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1FMwZtNxHJCTwPKuXKJ4ZsdSKUXpgIZCJ/preview\" width=\"1000\" height=\"300\"></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8IlH5EEWMwr5","colab_type":"code","colab":{}},"source":["bad_lg_data = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnmErOQHMw9M","colab_type":"code","colab":{}},"source":["# Discarding above bad entries\n","lg_data = lg_data[(~lg_data.isnull().any(axis=1)) & (lg_data['condition'] != '')].reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kknPQYxXi7Vj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876070648,"user_tz":-330,"elapsed":28715,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"f5f10e40-bbab-400d-b949-774a883a4248"},"source":["lg_data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(958653, 4)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"aMz5jmi4Rr3e","colab_type":"code","colab":{}},"source":["# Removing conditions with only 3 or more characters. Observed conditions 2 meaning conditions.(ny and md)\n","lg_data = lg_data[~lg_data['condition'].apply(lambda x: True if (len(x) < 3) else False)].reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zdylE_gLRsHn","colab_type":"text"},"source":["### Understanding intervention distribution"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D2e9DXdrO5FC","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876071166,"user_tz":-330,"elapsed":29179,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"ee8c31e7-7828-4a07-d8d9-e917607ea4dd"},"source":["lg_data['intervention'].nunique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14772"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jXUOlowXO5FH","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876071665,"user_tz":-330,"elapsed":29612,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"48a1d078-8860-4ec5-aed2-01fbca1cd9af"},"source":["lg_data['condition'].nunique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["596719"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"XadLnLoTPZEo","colab_type":"code","colab":{}},"source":["lg_dist = pd.DataFrame(lg_data['intervention'].value_counts())\n","lg_dist.reset_index(inplace=True)\n","lg_dist.reset_index(inplace=True)\n","lg_dist.columns = ['id', 'intervention', 'count']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wmDWxV8FQT29","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595876072207,"user_tz":-330,"elapsed":30088,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"8a3206ef-318b-4616-f008-5a2cd9f49e32"},"source":["lg_dist.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>intervention</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antibodies</td>\n","      <td>22897</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Paclitaxel</td>\n","      <td>22723</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Albumin-Bound Paclitaxel</td>\n","      <td>21169</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Bevacizumab</td>\n","      <td>20445</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Cyclophosphamide</td>\n","      <td>19981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id              intervention  count\n","0   0                Antibodies  22897\n","1   1                Paclitaxel  22723\n","2   2  Albumin-Bound Paclitaxel  21169\n","3   3               Bevacizumab  20445\n","4   4          Cyclophosphamide  19981"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"AS2tfA3eR-uK","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(20, 6))\n","# ax = sns.barplot(x=\"id\", y=\"count\", data=lg_dist)\n","# ax.set_yscale(\"log\")\n","# for ind, label in enumerate(ax.get_xticklabels()):\n","#     if ind % 2000 == 0:  # every 2000th label is kept\n","#         label.set_visible(True)\n","#     else:\n","#         label.set_visible(False)\n","# plt.savefig('lg_dist.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvbl6tRVSEGC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"ok","timestamp":1595876072208,"user_tz":-330,"elapsed":30008,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"d8f21df4-45e2-41a1-a548-9d2662856635"},"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1-X1jJu2_95-SjwqKcNY1ofsepiOJfnBA/preview\" width=\"1000\" height=\"300\"></iframe>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1-X1jJu2_95-SjwqKcNY1ofsepiOJfnBA/preview\" width=\"1000\" height=\"300\"></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"gslpTl2mRvc-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v6Ep9441TPVd","colab_type":"text"},"source":["### Keeping only unique conditions"]},{"cell_type":"code","metadata":{"id":"w69lg3Rlm2js","colab_type":"code","colab":{}},"source":["uq_lg_data = lg_data.copy()\n","lg_data = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpP2QJLWTPTY","colab_type":"code","colab":{}},"source":["uq_lg_data = uq_lg_data.drop_duplicates(subset=['condition'], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip1iKGrbUD1P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1595876072792,"user_tz":-330,"elapsed":30496,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"6157bfe8-18f9-4cf0-94f5-ba4aa5c00d85"},"source":["print(uq_lg_data.shape)\n","uq_lg_data.head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(596719, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>prescription</th>\n","      <th>intervention</th>\n","      <th>condition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri</td>\n","      <td>recombinant CD40-ligand</td>\n","      <td>melanoma skin diagnosis and no active cns metastases by ct scan or mri</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular</td>\n","      <td>Liposomal doxorubicin</td>\n","      <td>colorectal cancer diagnosis and cardiovascular</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement</td>\n","      <td>BI 836909</td>\n","      <td>multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen</td>\n","      <td>Immunoglobulins</td>\n","      <td>recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy</td>\n","      <td>Paclitaxel</td>\n","      <td>stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                                                                                                                                                                                                                                                                          prescription             intervention                                                                                                                                                                                                                                                   condition\n","0      0                                                                                                                                                                              study interventions are recombinant CD40-ligand . melanoma skin diagnosis and no active cns metastases by ct scan or mri  recombinant CD40-ligand                                                                                                                                                                                      melanoma skin diagnosis and no active cns metastases by ct scan or mri\n","1      0                                                                                                                                                                                                        study interventions are Liposomal doxorubicin . colorectal cancer diagnosis and cardiovascular    Liposomal doxorubicin                                                                                                                                                                                                              colorectal cancer diagnosis and cardiovascular\n","2      0                                                                                                                                    study interventions are BI 836909 . multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement                BI 836909                                                                                                                              multiple myeloma diagnosis and indwelling central venous cateder or willingness to undergo intra venous central line placement\n","3      0  study interventions are Immunoglobulins . recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen          Immunoglobulins  recurrent fallopian tube carcinoma diagnosis and patients are allowed to receive but are not required to receive two additional cytotoxic regimens for management of recurrent or persistent disease with no more than one non platinum non taxane regimen\n","4      0                                                                                                                                 study interventions are Paclitaxel . stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy               Paclitaxel                                                                                                                            stage ovarian cancer diagnosis and patients must have recovered from the effects of recent surgery radiotherapy or other therapy"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"LR_1lDMpUFhr","colab_type":"code","colab":{}},"source":["uq_lg_dist = pd.DataFrame(uq_lg_data['intervention'].value_counts())\n","uq_lg_dist.reset_index(inplace=True)\n","uq_lg_dist.reset_index(inplace=True)\n","uq_lg_dist.columns = ['id', 'intervention', 'count']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ob8H5bo5VNKc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595876072793,"user_tz":-330,"elapsed":30445,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"ed5b8876-adbb-4b6f-f11f-ba2b884d3934"},"source":["uq_lg_dist.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>intervention</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antibodies</td>\n","      <td>13839</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Paclitaxel</td>\n","      <td>13731</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Albumin-Bound Paclitaxel</td>\n","      <td>12867</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Bevacizumab</td>\n","      <td>12859</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Immunoglobulins</td>\n","      <td>11766</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id              intervention  count\n","0   0                Antibodies  13839\n","1   1                Paclitaxel  13731\n","2   2  Albumin-Bound Paclitaxel  12867\n","3   3               Bevacizumab  12859\n","4   4           Immunoglobulins  11766"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"ZlPnaWpcVPIi","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(20, 6))\n","# ax = sns.barplot(x=\"id\", y=\"count\", data=uq_lg_dist)\n","# ax.set_yscale(\"log\")\n","# for ind, label in enumerate(ax.get_xticklabels()):\n","#     if ind % 1000 == 0:  # every 2000th label is kept\n","#         label.set_visible(True)\n","#     else:\n","#         label.set_visible(False)\n","\n","# plt.savefig('unique_lg_dist.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fRERnF9j_LJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"ok","timestamp":1595876072797,"user_tz":-330,"elapsed":30350,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"c1adf676-c792-45a2-d418-ba29134c7dca"},"source":["%%html\n","<iframe src=\"https://drive.google.com/file/d/1cSaTfmpBFwKM1tQRdbI4t4r18kKUTtBF/preview\" width=\"1000\" height=\"300\"></iframe>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<iframe src=\"https://drive.google.com/file/d/1cSaTfmpBFwKM1tQRdbI4t4r18kKUTtBF/preview\" width=\"1000\" height=\"300\"></iframe>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"bPrFEN8RRuqg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SXIjVUO4se8","colab_type":"text"},"source":["### Minimal text fixes\n","\n","- Ending text sequences[Prescription, Condition] with a full stop.\n"]},{"cell_type":"code","metadata":{"id":"sbOWamfkkbXu","colab_type":"code","colab":{}},"source":["uq_lg_data['prescription'] = uq_lg_data['prescription'].astype(str) + \".\"\n","uq_lg_data['condition'] = uq_lg_data['condition'].astype(str) + \".\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6gOjGbORbEC","colab_type":"text"},"source":["## Train, Valid, Test sets"]},{"cell_type":"markdown","metadata":{"id":"uPP6bx1IWuAM","colab_type":"text"},"source":["Prepare Dataset\n","- ~~Stratified Train and Test sets for **uq_lg_data** based on target.~~\n","- ~~K-fold Cross-Validation dataset feeder (generator function)~~\n","- For downstream training task embeddings should be generated only once for\n","  - Prescription text sequences\n","  - Condition text sequences\n","\n","<!-- Generate BERT Embeddings for both prescription and condition\n","- [SVM] Use condition embeddings to predict interventions \n","- [SVM & DNN] Use Condition embeddings to predict eligibility\n","- [DNN] Use prescription embeddings to predict eligibility\n","- [DNN] Test if prescription and condition embeddigns obtained from mod_uq_lg_data text improves any performance. -->"]},{"cell_type":"code","metadata":{"id":"YJGC-lX7WuFv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876075634,"user_tz":-330,"elapsed":33109,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"28eca77a-2ebc-48c5-ce54-296a553d5b13"},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9m-MXxM7PPS7","colab_type":"text"},"source":["### Eligibility classifier datasets\n","\n","- Dataset 1: (X: Prescription, y: Eligibility)\n","- Dataset 2: (X: Condition, y: Eligibility)"]},{"cell_type":"code","metadata":{"id":"8aNtZ4Rf4hjf","colab_type":"code","colab":{}},"source":["eligbitliy_seed = 5\n","#rng = np.random.RandomState(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp-rxnj5YxLL","colab_type":"code","colab":{}},"source":["# Stratified split using same seed to match rows\n","pres_elg_X_train, pres_elg_X_test, pres_elg_y_train, pres_elg_y_test = train_test_split(uq_lg_data['prescription'], uq_lg_data['label'], test_size=0.20, random_state=eligbitliy_seed, stratify=uq_lg_data['label'])\n","cond_elg_X_train, cond_elg_X_test, cond_elg_y_train, cond_elg_y_test = train_test_split(uq_lg_data['condition'], uq_lg_data['label'], test_size=0.20, random_state=eligbitliy_seed, stratify=uq_lg_data['label'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VxW5a4n4tA8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595876076729,"user_tz":-330,"elapsed":34120,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"70f40dcb-8382-4ec4-cac5-0bd45be25471"},"source":["print(\"Label distribution across splits(Pres): \", uq_lg_data['label'].mean(), pres_elg_y_train.mean(), pres_elg_y_test.mean())\n","print(\"Label distribution across splits(Cond): \", uq_lg_data['label'].mean(), cond_elg_y_train.mean(), cond_elg_y_test.mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Label distribution across splits(Pres):  0.4847541305036374 0.4847551715108667 0.4847499664834428\n","Label distribution across splits(Cond):  0.4847541305036374 0.4847551715108667 0.4847499664834428\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MsbIA10x8nkr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876076730,"user_tz":-330,"elapsed":34089,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"8a7862bf-36a5-4c0b-bb69-b7f723d5d93e"},"source":["# Validate if row indices match\n","(pres_elg_X_train.index == cond_elg_X_train.index).mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"5OHtf7djYZ26","colab_type":"text"},"source":["Generate one-hot label matrix "]},{"cell_type":"code","metadata":{"id":"6oYicUtVYg7C","colab_type":"code","colab":{}},"source":["uq_lg_data_labels = to_categorical(uq_lg_data['label'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EA1jtFn9XnYK","colab_type":"code","colab":{}},"source":["# Use split index to get associated one hot matrix\n","pres_elg_y_train_labels = uq_lg_data_labels[pres_elg_y_train.index]\n","pres_elg_y_test_labels = uq_lg_data_labels[pres_elg_y_test.index]\n","\n","# Use split index to get associated one hot matrix\n","cond_elg_y_train_labels = uq_lg_data_labels[cond_elg_y_train.index]\n","cond_elg_y_test_labels = uq_lg_data_labels[cond_elg_y_test.index]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-wlCaVuPHUO","colab_type":"text"},"source":["### Intervention classifier dataset\n","\n","- Dataset: (X: Condition, y: Intervention)"]},{"cell_type":"code","metadata":{"id":"zsrCEMcp3zJw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876076732,"user_tz":-330,"elapsed":34023,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"705aad8d-f10e-4ae6-ac75-914bff950cfd"},"source":["# Total Interventions\n","uq_lg_dist.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14128"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"TRC2mxJ0rPU4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1595876076733,"user_tz":-330,"elapsed":33991,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"cb4d8af3-af59-48fa-8088-e8f0ce4718df"},"source":["# Condition counts for interventions summarized every 100(id) interval\n","uq_lg_dist[uq_lg_dist.id % 100 == 0][:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>intervention</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antibodies</td>\n","      <td>13839</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>100</td>\n","      <td>Epothilones</td>\n","      <td>1062</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>200</td>\n","      <td>BKM120</td>\n","      <td>346</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>300</td>\n","      <td>Dactinomycin</td>\n","      <td>176</td>\n","    </tr>\n","    <tr>\n","      <th>400</th>\n","      <td>400</td>\n","      <td>Sildenafil Citrate</td>\n","      <td>111</td>\n","    </tr>\n","    <tr>\n","      <th>500</th>\n","      <td>500</td>\n","      <td>Tivozanib</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>600</th>\n","      <td>600</td>\n","      <td>Light Infusion Therapyâ„¢</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>700</th>\n","      <td>700</td>\n","      <td>Phenobarbital</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>800</th>\n","      <td>800</td>\n","      <td>dietary intervention</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>900</th>\n","      <td>900</td>\n","      <td>Leukapheresis</td>\n","      <td>37</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id             intervention  count\n","0      0               Antibodies  13839\n","100  100              Epothilones   1062\n","200  200                   BKM120    346\n","300  300             Dactinomycin    176\n","400  400       Sildenafil Citrate    111\n","500  500                Tivozanib     80\n","600  600  Light Infusion Therapyâ„¢     63\n","700  700            Phenobarbital     52\n","800  800     dietary intervention     44\n","900  900            Leukapheresis     37"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"LFsS58JDqng6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1595876076733,"user_tz":-330,"elapsed":33948,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"c8c7ac2f-571e-43e1-defc-244e5db4f28d"},"source":["# Plot summarizing how the count drops\n","ax = sns.lineplot(x='id', y='count', data=uq_lg_dist[uq_lg_dist.id % 100 == 0][:10])\n","ax = sns.scatterplot(x='id', y='count', data=uq_lg_dist[:900], linewidth=0, hue=\"count\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Z0kFDeGU6cpJ","colab_type":"text"},"source":["Working with only first 150 interventions"]},{"cell_type":"code","metadata":{"id":"b8yOexd26ahH","colab_type":"code","colab":{}},"source":["# Specify top x interventions to consider\n","n_interventions = 150"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ana9A0lk0Y68","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595876076734,"user_tz":-330,"elapsed":33907,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"fa6644ef-5722-4905-df0c-3913463fe89d"},"source":["uq_lg_dist.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>intervention</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antibodies</td>\n","      <td>13839</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Paclitaxel</td>\n","      <td>13731</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Albumin-Bound Paclitaxel</td>\n","      <td>12867</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Bevacizumab</td>\n","      <td>12859</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Immunoglobulins</td>\n","      <td>11766</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id              intervention  count\n","0   0                Antibodies  13839\n","1   1                Paclitaxel  13731\n","2   2  Albumin-Bound Paclitaxel  12867\n","3   3               Bevacizumab  12859\n","4   4           Immunoglobulins  11766"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"WMKh9aGXwDff","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595876076735,"user_tz":-330,"elapsed":33882,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"2c416e40-3ef8-4400-a72b-a448afe6a400"},"source":["print(f\"It means we decided on interventions with at least {uq_lg_dist.loc[n_interventions, 'count']} condition entries\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["It means we decided on interventions with at least 525 condition entries\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wg6RiG36xWo1","colab_type":"code","colab":{}},"source":["# Inner join uq_lg_dist and uq_lg_data on intervention\n","temp_uq_lg_data = uq_lg_data.reset_index().merge(uq_lg_dist[uq_lg_dist['id'] < n_interventions], on='intervention').set_index('index') # Resetting and setting index to preserve df indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Sv8JGPcEfuu","colab_type":"code","colab":{}},"source":["temp_uq_lg_data_labels = to_categorical(temp_uq_lg_data['id'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATUcn84h4055","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1595876077252,"user_tz":-330,"elapsed":34341,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"4554b32b-ddfa-4712-987b-0b0037f68785"},"source":["temp_uq_lg_data_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"EPaEl1STJDJd","colab_type":"text"},"source":["Splitting to make intervention classifier dataset"]},{"cell_type":"code","metadata":{"id":"MPspQN-aKZXj","colab_type":"code","colab":{}},"source":["intervention_seed = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kFfl0r79JDHB","colab_type":"code","colab":{}},"source":["cond_intv_X_train, cond_intv_X_test, cond_intv_y_train, cond_intv_y_test = train_test_split(temp_uq_lg_data['condition'],\n","                                                                                            temp_uq_lg_data['id'],\n","                                                                                            test_size=0.20,\n","                                                                                            random_state=intervention_seed,\n","                                                                                            stratify=temp_uq_lg_data['id'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAHoi5fHw8rl","colab_type":"code","colab":{}},"source":["#temp_uq_lg_data.index.get_loc(121419)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEYeoP2iIi1g","colab_type":"code","colab":{}},"source":["# Use split index to get associated one hot matrix\n","cond_intv_y_train_labels = temp_uq_lg_data_labels[temp_uq_lg_data.index.get_indexer_for(cond_intv_y_train.index)]\n","cond_intv_y_test_labels = temp_uq_lg_data_labels[temp_uq_lg_data.index.get_indexer_for(cond_intv_y_test.index)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VLc8I9ykRMhp","colab_type":"text"},"source":["### K-Fold dataset feeder"]},{"cell_type":"code","metadata":{"id":"6iUbEwOn0xvo","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOrw7WUo0ZxL","colab_type":"code","colab":{}},"source":["# Specify number of k folds \n","k_folds_value = 7 # 2 or greater"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGwRKGqZRMen","colab_type":"code","colab":{}},"source":["kfold_seed = 15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"abN9Hz78yyDj","colab_type":"code","colab":{}},"source":["# Stratified K-Fold Generator\n","# This function must receive associated [df, embedding_matrix and one_hot_label_matrix] along with x & y column names\n","\n","def kfold_train_test_generator(dataset, x, y, k_splits, seed, embedding_matrix, one_hot_label_matrix):\n","  s_kf = StratifiedKFold(n_splits = k_splits, shuffle = True, random_state = seed)\n","  \n","  # Feeds X_train, X_test, y_train, y_test ... 'k_splits' times\n","  for idx, (train_indices, test_indices) in enumerate(s_kf.split(dataset[x], dataset[y])):\n","    print(f\"Split {idx} row count: Train [{train_indices.shape[0]}] ---- Test [{train_indices.shape[0]}]\")\n","\n","    yield (embedding_matrix[train_indices], embedding_matrix[test_indices],\n","          one_hot_label_matrix[train_indices], one_hot_label_matrix[test_indices])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G90W_Zu67G5N","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PhqJn7h47IWk","colab_type":"text"},"source":["### Validation sets (Only used while finetuning)"]},{"cell_type":"markdown","metadata":{"id":"eH5a0E9M-kMM","colab_type":"text"},"source":["Preiviously created training sets further split into training and validation sets.\n"," \n","[Split config: 90%-10%]"]},{"cell_type":"markdown","metadata":{"id":"kXoVoVfv8B2d","colab_type":"text"},"source":["y -> Eligibility"]},{"cell_type":"code","metadata":{"id":"n4XQmt6udlGD","colab_type":"code","colab":{}},"source":["# Stratified split using same seed to match rows\n","fine_pres_elg_X_train, fine_pres_elg_X_val, fine_pres_elg_y_train, fine_pres_elg_y_val = train_test_split(pres_elg_X_train, pres_elg_y_train, test_size=0.10, random_state=eligbitliy_seed, stratify=pres_elg_y_train)\n","fine_cond_elg_X_train, fine_cond_elg_X_val, fine_cond_elg_y_train, fine_cond_elg_y_val = train_test_split(cond_elg_X_train, cond_elg_y_train, test_size=0.10, random_state=eligbitliy_seed, stratify=cond_elg_y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkPiy2pc8YKB","colab_type":"text"},"source":["y -> Intervention"]},{"cell_type":"code","metadata":{"id":"0V2m2_eT8Xdl","colab_type":"code","colab":{}},"source":["fine_cond_intv_X_train, fine_cond_intv_X_val, fine_cond_intv_y_train, fine_cond_intv_y_val = train_test_split(cond_intv_X_train,\n","                                                                                            cond_intv_y_train,\n","                                                                                            test_size=0.10,\n","                                                                                            random_state=intervention_seed,\n","                                                                                            stratify=cond_intv_y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lO_t5TJEq_sP","colab_type":"text"},"source":["### Outputtting all finetuning dfs"]},{"cell_type":"code","metadata":{"id":"Y5Q0j_lxvUTu","colab_type":"code","colab":{}},"source":["# pd.concat([fine_pres_elg_X_train, fine_pres_elg_y_train], axis = 1).reset_index(drop=True).to_csv('task1_pres_elg_train.csv', index=False)\n","# pd.concat([fine_pres_elg_X_val, fine_pres_elg_y_val], axis = 1).reset_index(drop=True).to_csv('task1_pres_elg_val.csv', index=False)\n","# pd.concat([pres_elg_X_test, pres_elg_y_test], axis = 1).reset_index(drop=True).to_csv('task1_pres_elg_test.csv', index=False)\n","# pd.concat([fine_cond_elg_X_train, fine_cond_elg_y_train], axis = 1).reset_index(drop=True).to_csv('task2_cond_elg_train.csv', index=False)\n","# pd.concat([fine_cond_elg_X_val, fine_cond_elg_y_val], axis = 1).reset_index(drop=True).to_csv('task2_cond_elg_val.csv', index=False)\n","# pd.concat([cond_elg_X_test, cond_elg_y_test], axis = 1).reset_index(drop=True).to_csv('task2_cond_elg_test.csv', index=False)\n","# pd.concat([fine_cond_intv_X_train, fine_cond_intv_y_train], axis = 1).reset_index(drop=True).to_csv('task3_cond_intv_train.csv', index=False)\n","# pd.concat([fine_cond_intv_X_val, fine_cond_intv_y_val], axis = 1).reset_index(drop=True).to_csv('task3_cond_intv_val.csv', index=False)\n","# pd.concat([cond_intv_X_test, cond_intv_y_test], axis = 1).reset_index(drop=True).to_csv('task3_cond_intv_test.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCHm2PFVvfsj","colab_type":"text"},"source":["Uploading to Google drive"]},{"cell_type":"code","metadata":{"id":"1jT3JNDNvi9h","colab_type":"code","colab":{}},"source":["task_csv_filenames = ['task1_pres_elg_train.csv', 'task1_pres_elg_val.csv', 'task1_pres_elg_test.csv', 'task2_cond_elg_train.csv', 'task2_cond_elg_val.csv', 'task2_cond_elg_test.csv', 'task3_cond_intv_train.csv', 'task3_cond_intv_val.csv', 'task3_cond_intv_test.csv']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LakcQqwTv4bm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1595879239055,"user_tz":-330,"elapsed":2172,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"13506512-9624-42b1-9824-ca7ca278246a"},"source":["for csv_filename in task_csv_filenames:\n","  save_to_drive(from_dir_path=f'{csv_filename}', to_path=\"/content/drive/My Drive/model_csv_files/bert\", folder_prefix=\"\", from_is_file=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n","Saving model on google drive...\n","Model saved.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JzuCbUwadlul","colab_type":"text"},"source":["## Finetuning BERT"]},{"cell_type":"markdown","metadata":{"id":"FpYup1EHdw3I","colab_type":"text"},"source":["### Objective\n","Finetune BERT for 3 seperate tasks:\n","- **`Task 1`** Input: Prescription -> Output: Eligibility (Binary)\n","- **`Task 2`** Input: Condition -> Output: Eligibility (Binary)\n","- **`Task 3`** Input: Condition ->  Output: Intervention (Multi class)"]},{"cell_type":"markdown","metadata":{"id":"QX8UG0Z1UnVC","colab_type":"text"},"source":["BERT Finetuning task: Sequence Classification\n","\n","Using ['BertForSequenceClassification'](https://huggingface.co/transformers/model_doc/bert.html#tfbertforsequenceclassification) interface from [huggingface](https://huggingface.co/)"]},{"cell_type":"markdown","metadata":{"id":"uOKGmUUt2WA0","colab_type":"text"},"source":["### Prerequisites "]},{"cell_type":"markdown","metadata":{"id":"BEqWeLsD2y5z","colab_type":"text"},"source":["Detect GPU"]},{"cell_type":"code","metadata":{"id":"08pQJNXI3JXk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595833335076,"user_tz":-330,"elapsed":39707,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"ec901bcb-605c-4fc9-bac1-0c143fee981b"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name\n","device_name = tf.test.gpu_device_name()\n","\n","if device_name == '/device:GPU:0':\n","  print(f'Found GPU at {device_name}')\n","else:\n","  raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m8NV2t5L4LiH","colab_type":"text"},"source":["Import PyTorch and specify GPU as a device to use"]},{"cell_type":"code","metadata":{"id":"lMoCh5mH4gEE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595833335077,"user_tz":-330,"elapsed":39675,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"b4ea50a1-ab65-41f3-9ed5-1a5e0fda272c"},"source":["import torch\n","\n","# Check if GPU is avaiable\n","if torch.cuda.is_available():\n","  # Make PyTorch use the GPU\n","  device = torch.device(\"cuda\")\n","\n","  print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","  print(f'We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","  print('No GPU available, using the CPU instead')\n","  device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGETp8j-JcFc","colab_type":"text"},"source":["Install Apex"]},{"cell_type":"code","metadata":{"id":"pLEO4EaPHdQt","colab_type":"code","colab":{}},"source":["# %%writefile setup.sh\n","\n","# git clone https://github.com/NVIDIA/apex\n","# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oywB0bvmGT2i","colab_type":"code","colab":{}},"source":["# !sh setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svYH3lPKJhCS","colab_type":"code","colab":{}},"source":["# from apex import amp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uph2XfnZDhOU","colab_type":"text"},"source":["Install HuggingFace Library"]},{"cell_type":"code","metadata":{"id":"MN_1dOMKECwP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1595833344906,"user_tz":-330,"elapsed":49420,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"4e6bc7af-16e1-465b-9f17-a9e214f1310a"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 2.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 24.5MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 18.5MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 39.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=87159e9dbfc0c2e3d556dbbbc120fef086be0321467eeb03cc9958db0c4543cd\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C57F08bMEH-J","colab_type":"text"},"source":["### Dataset info\n","\n","\n",">Task No. | Mode | Input | Input Shape | Output | Output Shape\n",">--- | --- | --- | --- | --- | ---\n",">1 | Training | fine_pres_elg_X_train | (429636,) | fine_pres_elg_y_train | (429636,)\n",">  | | fine_pres_elg_X_val | (47738,) | fine_pres_elg_y_val | (47738,)\n",">  | Testing | pres_elg_X_test | (119344,) | pres_elg_y_test | (119344,)\n",">2 | Training | fine_cond_elg_X_train | (429636,)  | fine_cond_elg_y_train | (429636,)\n",">  | | fine_cond_elg_X_val | (47738,) | fine_cond_elg_y_val | (47738,)\n",">  | Testing | cond_elg_X_test | (119344,) | cond_elg_y_test | (119344,)\n",">3 | Training | fine_cond_intv_X_train | (317174,)  | fine_cond_intv_y_train | (317174,)\n",">  | | fine_cond_intv_X_val | (35242,) | fine_cond_intv_y_val | (35242,)\n",">  | Testing | cond_intv_X_test |  (88105,) | cond_intv_y_test | (88105,)"]},{"cell_type":"markdown","metadata":{"id":"24IymAG_RF1Q","colab_type":"text"},"source":["### Pretrained Models Info\n","\n",">Architecture | Model shortcut name | Details of the model\n",">--- | --- | --- \n","> BERT | bert-base-uncased | 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on lower-cased English text.\n",">  | bert-large-uncased | 24-layer, 1024-hidden, 16-heads, 340M parameters. Trained on lower-cased English text."]},{"cell_type":"markdown","metadata":{"id":"-7D1RjQyNdpB","colab_type":"text"},"source":["### Tokenization & Input Formatting"]},{"cell_type":"markdown","metadata":{"id":"AO8yFXAxN4ia","colab_type":"text"},"source":["Transforming datasets into a format BERT can be trained on\n","\n","Input format expected for each sequence: `\"[CLS] text_sequence [SEP]\"`"]},{"cell_type":"markdown","metadata":{"id":"UrjkMinOOEje","colab_type":"text"},"source":["#### Load BERT Tokenizer"]},{"cell_type":"markdown","metadata":{"id":"otwtpcdNOQrQ","colab_type":"text"},"source":["Text is split into tokens, and then these tokens are mapped to their index as per the BERT Tokenizer vocabulory. We try both cased(case preserved) and uncased(no casing/lowercase) version of Tokenizer."]},{"cell_type":"code","metadata":{"id":"6_oID9_aPWia","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MU77acg0Pan4","colab_type":"code","colab":{}},"source":["# Download and load BERT tokenizer\n","def get_bert_tokenizer():\n","  tokenizer = BertTokenizer.from_pretrained(model_config['model_name'], do_lower_case=True)\n","  return tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bv_Xcu0GTYW7","colab_type":"text"},"source":["#### Maximum sequence length identifier"]},{"cell_type":"code","metadata":{"id":"rW2GHLn1TsCm","colab_type":"code","colab":{}},"source":["def get_max_seq_length(X):\n","  max_len = 0\n","\n","  # Iterate through each sequece\n","  for sent in X.values:\n","\n","    # Tokenizing the text and add '[CLS]' and '[SEP]' tokens to identify length.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length\n","    max_len = max(max_len, len(input_ids))\n","\n","  print(f'Max sequence length: ', max_len)  \n","  return max_len"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YVlD63DJXBdI","colab_type":"text"},"source":["#### Input Prep Function \n","\n","We encode sentences using utility function developed by HuggingFace. That does more than simply encoding the sequences.\n","\n","     `tokenizer.encode_plus` will:\n","       (1) Tokenize the sentence.\n","       (2) Prepend the `[CLS]` token to the start.\n","       (3) Append the `[SEP]` token to the end.\n","       (4) Map tokens to their IDs.\n","       (5) Pad or truncate the sentence to `max_length`\n","       (6) Create attention masks for [PAD] tokens. (simply an array of 1s and 0s indicating which tokens are padding and which arenâ€™t)\n","\n"]},{"cell_type":"code","metadata":{"id":"C3MS2veKXztX","colab_type":"code","colab":{}},"source":["# Tokenize all the sentences and map the tokens to their word IDs.\n","def prepare_input(X, labels, input_max_len, truncation=True, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt', print_complete_status=True):\n","  # Containers\n","  input_ids = []\n","  attention_masks = []\n","  \n","  # Iterate through each sequece\n","  for sent in X.values:\n","    # encod_plus() returns a dict\n","    encoded_dict = tokenizer.encode_plus(\n","        sent,\n","        add_special_tokens = True,                      # Add '[CLS]' and '[SEP]'\n","        max_length = input_max_len,\n","        truncation=truncation,\n","        pad_to_max_length = pad_to_max_length,          # Pad & truncate all sentences.\n","        return_attention_mask = return_attention_mask,  # Construct attn. masks.\n","        return_tensors = return_tensors,                # Return pytorch tensors.\n","    )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    # Also its attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","  \n","  # Convert list into tensor\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  labels = torch.tensor(labels.values)\n","  \n","  if print_complete_status:\n","    print(f'Input Ready!')\n","  return (input_ids, attention_masks, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4eGVd_jKhTTO","colab_type":"text"},"source":["### Dataset Wrapper and Iterator"]},{"cell_type":"markdown","metadata":{"id":"arx3PaNXjYpD","colab_type":"text"},"source":["Wrap data into a TensorDataset and create an iterator for it using DataLoader (This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory.)"]},{"cell_type":"code","metadata":{"id":"EZZrUPO0jwVH","colab_type":"code","colab":{}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOQSj58VkEUF","colab_type":"code","colab":{}},"source":["def data_wrapper_iterator(input_ids, attention_masks, labels, sampler_type):\n","  \"\"\"\n","  sampler_types: ['sequential', 'random}\n","\n","  sequential: used when order doesnt matter\n","  random: used when training samples\n","  \"\"\"\n","\n","  # Combine the training input into a TensorDataset\n","  dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","  dataloader = None\n","\n","  # Create iterator(DataLoader) for dataset\n","  if (sampler_type == \"sequential\"):\n","    dataloader = DataLoader(\n","        dataset,\n","        sampler = SequentialSampler(dataset),\n","        batch_size = model_config['batch_size']\n","    )\n","  else:\n","    dataloader = DataLoader(\n","        dataset,\n","        sampler = RandomSampler(dataset),\n","        batch_size = model_config['batch_size']\n","    )\n","  return (dataset, dataloader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2CHNGakofzO","colab_type":"text"},"source":["### Classification Model"]},{"cell_type":"markdown","metadata":{"id":"HiSmfyeMpvPI","colab_type":"text"},"source":["The huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\n","We'll be using \n","\n","`BertForSequenceClassification`. This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task."]},{"cell_type":"code","metadata":{"id":"CD5l1V33p3e2","colab_type":"code","colab":{}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-z5IfrnoqT_s","colab_type":"code","colab":{}},"source":["def define_classification_model(num_labels):\n","  # Load BertForSequenceClassification, the pretrained BERT model with a single \n","  # linear classification layer on top.\n","  model = BertForSequenceClassification.from_pretrained(\n","      model_config['model_name'],\n","      num_labels = num_labels,\n","      output_attentions = False, # Whether the model returns attentions weights.\n","      output_hidden_states = False, # Whether the model returns all hidden states\n","  )\n","\n","  # Make the model run on GPU\n","  model.cuda()\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6Lxh0PHsEbM","colab_type":"code","colab":{}},"source":["# Print Params\n","def print_model_params_overview(model):\n","  params = list(model.named_parameters())\n","  print(f'The BERT model has {len(params):} different named parameters.\\n')\n","\n","  print('==== Embedding Layer ====\\n')\n","  for p in params[0:5]:\n","      print(f\"{p[0]:<55} {str(tuple(p[1].size())):>12}\")\n","\n","  print('\\n==== First Transformer ====\\n')\n","  for p in params[5:21]:\n","      print(f\"{p[0]:<55} {str(tuple(p[1].size())):>12}\")\n","\n","  print('\\n==== Output Layer ====\\n')\n","  for p in params[-4:]:\n","      print(f\"{p[0]:<55} {str(tuple(p[1].size())):>12}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AZ1qCr9Ysxhd","colab_type":"text"},"source":["### Optimizer & Learning rate scheduler"]},{"cell_type":"code","metadata":{"id":"8CIrdxW3s_mN","colab_type":"code","colab":{}},"source":["# Retrieve and modify pretrained model's training hyper parameters\n","# Initialize Adam Optimizer\n","def get_adam_optimizer(model):\n","  optimizer = AdamW(\n","      model.parameters(),\n","      lr = model_config['learning_rate'], # default is 5e-5,\n","      eps = model_config['eps']           # default is 1e-8\n","  )\n","  return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLIq7rANwGjk","colab_type":"code","colab":{}},"source":["from transformers import get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PGQLrxrvkN_","colab_type":"code","colab":{}},"source":["def get_linear_learning_rate_scheduler(model, optimizer, dataloader, grad_accumulation_steps=1):\n","  # Determine total number of training steps\n","  # [number of batches in an epoch] x [number of epochs]\n","  total_steps = (len(dataloader) * grad_accumulation_steps) * model_config['n_epochs']\n","\n","  # Learning rate scheduler\n","  scheduler = get_linear_schedule_with_warmup(\n","      optimizer,\n","      num_warmup_steps = 0,\n","      num_training_steps = total_steps\n","  )\n","\n","  return scheduler\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8pOuKeYxJtf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rj0AhOJ0xKv9","colab_type":"text"},"source":["### Helper Functions\n","- Measure Accuracy\n","- Measure Elapsed Time"]},{"cell_type":"code","metadata":{"id":"Sl6UFRPRxkdr","colab_type":"code","colab":{}},"source":["def get_accuracy(preds, labels):\n","  '''\n","  Compute mean accuracy \n","  '''\n","  pred = np.argmax(preds, axis=1).flatten()\n","  labels = labels.flatten()\n","\n","  return np.sum(pred == labels) / len(labels) # mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwJF9zbt5u6R","colab_type":"code","colab":{}},"source":["def format_time(elapsed):\n","  '''\n","  Takes a time in seconds and returns a string hh:mm:ss\n","  '''\n","  # Round to the nearest second.\n","  elapsed_rounded = int(round((elapsed)))\n","  \n","  # Format as hh:mm:ss\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGmC69mC6EwI","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jKZl27i6FR2","colab_type":"text"},"source":["### Trainer & Validator"]},{"cell_type":"code","metadata":{"id":"7A0N8SynAEda","colab_type":"code","colab":{}},"source":["def train(model, train_dataloader, tokenizer, optimizer, scheduler, seed_value,\n","          validation_dataloader=None, use_validation=True, grad_accumulation_steps=1, output_dir_name='model_save', save_on_gdrive=True):\n","  # If validation is true check if validation_dataloader is supplied, raise error if not\n","  if use_validation and (validation_dataloader == None):\n","    raise SystemError('validation_dataloader needed to perform validation!')\n","\n","  # Seed RNGs\n","  random.seed(seed_value)\n","  np.random.seed(seed_value)\n","  torch.manual_seed(seed_value)\n","  torch.cuda.manual_seed_all(seed_value)\n","\n","  # Container to store loss and accuracy for each training and validation phase\n","  # Along with batch intervals and epochs.\n","  stats = []\n","\n","  # Training start time\n","  init_time = time.time()\n","\n","  for epoch_i in range(0, model_config['n_epochs']):\n","    # Cycle of our classifier epoch (Train->Update)->Validate\n","\n","    print(f\"\\n{'=='*5} Epoch {epoch_i + 1} / {model_config['n_epochs']} {'=='*5}\")\n","    print(\"Training...\")\n","    \n","    # Epoch start time\n","    t0 = time.time()\n","\n","    # Loss is accumulated and averaged across batches for each epoch\n","    # We clear the loss for each new epoch\n","    total_train_loss = 0\n","\n","    # Enable training mode\n","    model.train()\n","\n","    # Clear previously computed gradients for new epoch\n","    model.zero_grad()\n","\n","    # total_mini_batch_loss, used for accumulating loss over mini steps\n","    total_mini_batch_loss = 0\n","\n","    # Record steps completed, used for computed average training loss\n","    steps_completed = 0\n","\n","    # Iterate over all the batches in train_dataloader\n","    for step, batch in enumerate(train_dataloader):\n","\n","      # Print progress every 3% batches completed\n","      if step % 300 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print(f'  Batch {step:>5}  of  {len(train_dataloader):>5}.    Elapsed: {elapsed:}.')\n","\n","      # Unpack training batch from train_dataloader\n","      # Batch contains 3 PyTorch tensors (input_ids, attention_masks, labels)\n","      # Place each tensor on GPU using to\n","      b_input_ids = batch[0].to(device)\n","      b_attention_mask = batch[1].to(device)\n","      b_labels = batch[2].to(device)\n","\n","      # Perform forward pass\n","      loss, logits = model(b_input_ids,\n","                           token_type_ids=None,\n","                           attention_mask=b_attention_mask,\n","                           labels=b_labels)\n","      \n","      # # Accumulate the training loss across all the batches\n","      # total_train_loss += loss.item()\n","\n","      # Accumulate mini_batch_loss\n","      total_mini_batch_loss += loss.item()\n","\n","      # # Clear previously computed gradients # MOD: Don't Clear gradients\n","      # model.zero_grad()\n","\n","      # # Perform backward pass using loss to compute the gradient vector \n","      # # Simply let the gradients accumulate according to grad_accumulation_steps value\n","      # loss.backward()\n","      # Use mixed precision backprop\n","      with amp.scale_loss(loss, optimizer) as scaled_loss:                      \n","        scaled_loss.backward()\n","\n","      # # Fix for Exploding gradients: Normalize them between 1 and 0\n","      # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      # Perform Mini-Batch gradient accumulation\n","      if (step+1) % grad_accumulation_steps == 0:\n","\n","        # # Fix for Exploding gradients: Normalize them between 1 and 0\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Accumulate the training loss across all the batches\n","        total_train_loss += (total_mini_batch_loss / grad_accumulation_steps)\n","\n","        # Update parameters using accumulated gradients and Adaptive learning rate\n","        optimizer.step()\n","\n","        # Update the learning rate\n","        scheduler.step()\n","\n","        # Clear accumulated gradients\n","        model.zero_grad()\n","\n","        # Reset total_mini_batch_loss\n","        total_mini_batch_loss = 0\n","\n","        # Increment steps_completed by 1, because we updated our params\n","        steps_completed += 1\n","\n","    # Average the accumulated loss over all the steps\n","    avg_train_loss = total_train_loss / steps_completed\n","\n","    # Compute time taken for train in this epoch\n","    training_time = format_time(time.time() - t0)\n","\n","    print(f\"\\n  Training loss: {avg_train_loss:.2f}\")\n","    print(f\"  Training took: {training_time:}\\n\")\n","\n","    if use_validation:\n","      print(\"Running Validation...\")\n","\n","      t0 = time.time()\n","\n","      # Enable evaluation mode\n","      model.eval()\n","\n","      # Performance variables\n","      total_eval_accuracy = 0\n","      total_eval_loss = 0\n","      nb_eval_steps = 0\n","\n","      for batch in validation_dataloader:\n","        # Unpack batch to GPU\n","        b_input_ids = batch[0].to(device)\n","        b_attention_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Since we dont do backprop while validation we dont need to build compute graph\n","        with torch.no_grad():\n","\n","          # Perform forward pass\n","          loss, logits = model(b_input_ids,\n","                              token_type_ids=None,\n","                              attention_mask=b_attention_mask,\n","                              labels=b_labels)\n","          \n","        # Accumulate the validation loss across batches\n","        total_eval_loss += loss.item()\n","\n","        # # Move logits and labels to CPU # Bad Practice\n","        # logits = logits.detach().cpu().numpy()\n","        # label_ids = b_labels.to('cpu').numpy()\n","\n","        logits = logits.numpy()\n","        label_ids = b_labels.numpy()\n","\n","        # Calculate accuracy for this batch and accumulate\n","        total_eval_accuracy += get_accuracy(logits, label_ids)\n","\n","      # Print avg accuracy for this validation \n","      avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","      print(f\"  Accuracy: {avg_val_accuracy:.2f}\")\n","\n","      # Compute avg loss over all the batches\n","      avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","      # Compute time taken for Validation in this epoch\n","      validation_time = format_time(time.time() - t0)\n","\n","      print(f\"  Validation Loss: {avg_val_loss:.2f}\")\n","      print(f\"  Validation took: {validation_time:}\")\n","\n","    # Store all the stats for this epoch\n","    stats_dict = {\n","      'epoch': (epoch_i + 1),\n","      'Training Loss': avg_train_loss,\n","      'Training Time': training_time,\n","    }\n","\n","    if use_validation:\n","      stats_dict['Valid. Loss'] = avg_val_loss\n","      stats_dict['Valid. Accur.'] = avg_val_accuracy\n","      stats_dict['Validation Time'] = validation_time\n","\n","    stats.append(stats_dict)\n","\n","  print(\"\\nTraining complete!\")\n","  print(f\"Total training took {format_time(time.time()-total_t0):} (h:mm:ss)\")\n","\n","  # Save the model\n","  save_model(model=model, tokenizer=tokenizer, output_dir_name=output_dir_name, on_gdrive=save_on_gdrive)\n","\n","  return stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CiI_G1oWrHk8","colab_type":"text"},"source":["Summarize Finetuning Training Performance"]},{"cell_type":"code","metadata":{"id":"zF13oGnzlaYn","colab_type":"code","colab":{}},"source":["def summarize_training_stats(stats):\n","  stats_df = pd.DataFrame(stats).set_index('epoch')\n","  stats_df.style.format('{:.2f}')\n","\n","  sns.set(style='darkgrid')\n","  sns.set(font_scale=1.5)\n","  plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","  plt.plot(stats_df['Training Loss'], 'b-o', label=\"Training\")\n","  if 'Valid. Loss' in stats:\n","    plt.plot(stats_df['Valid. Loss'], 'g-o', label=\"Validation\")\n","  \n","  plt.title(\"Loss Plot\")\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Loss\")\n","  plt.legend()\n","  plt.xticks([1, 2, 3, 4])\n","  plt.show()\n","\n","  return stats_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAd15-8Mu4GA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_sz0zWG-vc0c","colab_type":"text"},"source":["### Prediction function"]},{"cell_type":"code","metadata":{"id":"aGMXkVoJvr3d","colab_type":"code","colab":{}},"source":["def predict(model, dataloader):\n","  print(\"Running Validation...\")\n","\n","  # Enable evaluation mode\n","  model.eval()\n","\n","  # Output container variables\n","  predictions = []\n","  true_labels = []\n","\n","  for batch in dataloader:\n","    # Unpack batch to GPU\n","    b_input_ids = batch[0].to(device)\n","    b_attention_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","\n","    # Since we dont do backprop while predicting, we dont need to build compute graph, Speed UP!\n","    with torch.no_grad():\n","\n","      # Perform forward pass\n","      outputs = model(b_input_ids,\n","                     token_type_ids=None,\n","                     attention_mask=b_attention_mask)\n","      \n","    logits = output[0]\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","\n","  print('Predictions done!')\n","\n","  return (predictions, true_labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGjEHv3e1BRz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06lrmvnycsq-","colab_type":"text"},"source":["### Model Saver"]},{"cell_type":"code","metadata":{"id":"Kf-S4K0FdQAU","colab_type":"code","colab":{}},"source":["def save_model(model, tokenizer, output_dir_name='model_save', on_gdrive=False):\n","  output_dir = f'./{output_dir_name}/'\n","  # Create output directory if doesn't exist\n","  if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","  print(f\"Saving model to /{output_dir} ....\")\n","  # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","  # They can then be reloaded using `from_pretrained()`\n","  model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","  model_to_save.save_pretrained(output_dir)\n","  tokenizer.save_pretrained(output_dir)\n","  print(\"Model saved on colab instance.\")\n","  if on_gdrive:\n","    save_to_drive(from_dir_path=output_dir_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJn1Sk0FfP_3","colab_type":"code","colab":{}},"source":["def save_to_drive(from_dir_path='model_save', to_path=\"/content/drive/My Drive/trained_model_files\", folder_prefix=\"bert\", from_is_file=False):\n","  print(f'Saving model on google drive...')\n","  from_dir = f\"{from_dir_path}\"\n","  to_dir = f\"{to_path}/{folder_prefix}_{from_dir}\"\n","  try:\n","    if from_is_file:\n","      to_dir = f\"{to_path}/\"\n","      if not os.path.exists(to_dir):\n","        os.makedirs(to_dir)\n","      shutil.copy2(from_dir, to_dir)\n","    else:\n","      if not os.path.exists(to_dir):\n","        os.makedirs(to_dir)\n","      copy_tree(from_dir, to_dir)\n","    print(f'Model saved.')\n","  except:\n","    print(f\"Copy to Google drive failed: {sys.exc_info()[-2:]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWSL45Oy1LNL","colab_type":"text"},"source":["### Run Finetune"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rCZ_-kr_KH7e"},"source":["#### Dataset info\n","\n","\n",">Task No. | Mode | Input | Input Shape | Output | Output Shape\n",">--- | --- | --- | --- | --- | ---\n",">1 | Training | fine_pres_elg_X_train | (429636,) | fine_pres_elg_y_train | (429636,)\n",">  | | fine_pres_elg_X_val | (47738,) | fine_pres_elg_y_val | (47738,)\n",">  | Testing | pres_elg_X_test | (119344,) | pres_elg_y_test | (119344,)\n",">2 | Training | fine_cond_elg_X_train | (429636,)  | fine_cond_elg_y_train | (429636,)\n",">  | | fine_cond_elg_X_val | (47738,) | fine_cond_elg_y_val | (47738,)\n",">  | Testing | cond_elg_X_test | (119344,) | cond_elg_y_test | (119344,)\n",">3 | Training | fine_cond_intv_X_train | (317174,)  | fine_cond_intv_y_train | (317174,)\n",">  | | fine_cond_intv_X_val | (35242,) | fine_cond_intv_y_val | (35242,)\n",">  | Testing | cond_intv_X_test |  (88105,) | cond_intv_y_test | (88105,)"]},{"cell_type":"markdown","metadata":{"id":"oltOPbeQwPSe","colab_type":"text"},"source":["Some task independent declarations "]},{"cell_type":"code","metadata":{"id":"NLQX3DwXzcmP","colab_type":"code","colab":{}},"source":["def create_input_tensor_task_dir(task_num):\n","  if not os.path.exists(\"input_tensors\"):\n","    os.makedirs(f\"input_tensors\")\n","  os.makedirs(f\"input_tensors/task_{task_num}\")  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLiCAZzK06jt","colab_type":"code","colab":{}},"source":["def remove_input_tensors(del_input_task_num=None):\n","  if del_input_task_num != None:\n","    shutil.rmtree(f\"input_tensors/task_{del_input_task_num}\")\n","    if (len(os.listdir(\"input_tensors/\")) == 0):\n","      shutil.rmtree(\"input_tensors\")\n","  else:\n","    shutil.rmtree(\"input_tensors\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqYcgqWU1lUR","colab_type":"code","colab":{}},"source":["def del_directory_tree(folder_name):\n","  shutil.rmtree(f\"{folder_name}\")\n","  print(f\"{folder_name} tree deleted.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26dWqxPQ-VMF","colab_type":"code","colab":{}},"source":["# create_input_tensor_task_dir(task_num=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shWxTA3S3wVR","colab_type":"code","colab":{}},"source":["# remove_input_tensors(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y7IuFZcC1UsU"},"source":["#### Model Config"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MBZbbvlc1UsV","colab":{}},"source":["model_config = {\n","    \"model_name\": \"bert-base-uncased\",\n","    \"batch_size\": 16,\n","    \"n_epochs\": 1,\n","    \"learning_rate\": 5e-5,\n","    \"eps\": 1e-8,\n","    'grad_accumulation_steps': 1\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr0iQPEe5gHY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["ab8e01838c5048b3a1345f01118fa230","3864f8a2dd2541debe0acab6fe13a0c3","385e02c062824a6f8fc1a9fd3d0adc90","b65c73d5edc64a87a7e0d8342693c1ee","6eaa28b45bf04938bee2e59ed393cfe9","ae3de1e34b584377bb9f692b7ec83d0e","8bdb815658fd4b3595ab3a42ec405f5a","24a1f6a407b24c819cbff4b01e631cf2"]},"executionInfo":{"status":"ok","timestamp":1595833347855,"user_tz":-330,"elapsed":51699,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"0a668fb3-6b5c-4e6b-c5fc-08fe2a418d0c"},"source":["tokenizer = get_bert_tokenizer()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab8e01838c5048b3a1345f01118fa230","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f2Z8J66yDxmf","colab_type":"text"},"source":["**Max token lengths discovered in below section**\n","\n","Task 1:(pres -> elg) max_len = `410`\n","  - fine_pres_elg_X_train -> 408\n","  - fine_pres_elg_X_val -> 267\n","  - pres_elg_X_test -> 277\n","\n","Task 2:(cond -> elg) max_len = `392`\n","  - fine_cond_elg_X_train -> 390\n","  - fine_cond_elg_X_val -> 249\n","  - cond_elg_X_test -> 268\n","\n","Task 3:(cond -> intv) max_len = `271`\n","  - fine_cond_intv_X_train -> 269\n","  - fine_cond_intv_X_val -> 245\n","  - cond_intv_X_test -> 263\n"]},{"cell_type":"code","metadata":{"id":"q95XBCizNcZl","colab_type":"code","colab":{}},"source":["task1_max_len = 410\n","task2_max_len = 392\n","task3_max_len = 271"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CFUV01CUNnNK","colab_type":"text"},"source":["#### Discover max token length for each task"]},{"cell_type":"code","metadata":{"id":"WknOsSahAsBn","colab_type":"code","colab":{}},"source":["# pTrain_max_len = get_max_seq_length(fine_pres_elg_X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kGaN10zAtEx","colab_type":"code","colab":{}},"source":["# pTest_max_len = get_max_seq_length(fine_pres_elg_X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvcCVew1K2yV","colab_type":"code","colab":{}},"source":["# pEval_max_len = get_max_seq_length(pres_elg_X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZF4m5hr3K6a-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WqtF26H7Z-c","colab_type":"code","colab":{}},"source":["# cTrain_max_len = get_max_seq_length(fine_cond_elg_X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sgu9K1oC8GXg","colab_type":"code","colab":{}},"source":["# cTest_max_len = get_max_seq_length(fine_cond_elg_X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QgNiQxKK7j3","colab_type":"code","colab":{}},"source":["# cEval_max_len = get_max_seq_length(cond_elg_X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSwN2s34K_De","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlP-nc18K_UV","colab_type":"code","colab":{}},"source":["# cintTrain_max_len = get_max_seq_length(fine_cond_intv_X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5BOGdtmCLWOW","colab_type":"code","colab":{}},"source":["# cintTest_max_len = get_max_seq_length(fine_cond_intv_X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RI_bZp-LWwp","colab_type":"code","colab":{}},"source":["# cintEval_max_len = get_max_seq_length(cond_intv_X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_lt5bepoGAh0","colab_type":"text"},"source":["#### Token distribution analysis"]},{"cell_type":"code","metadata":{"id":"sF3quur8E4ZV","colab_type":"code","colab":{}},"source":["def get_token_dist_dict(X, y):\n","  token_dist_dict = {\n","      'index': [],\n","      'token_count': []\n","  }\n","  for idx in range(X.shape[0]):\n","    in_ids, _, _ = prepare_input(X=X[idx:idx+1],\n","                                labels=y[idx:idx+1],\n","                                input_max_len=None,\n","                                truncation=False,\n","                                pad_to_max_length=False,\n","                                return_attention_mask=None,\n","                                return_tensors='pt',\n","                                print_complete_status=False)\n","    token_dist_dict['index'].append(idx)\n","    token_dist_dict['token_count'].append(len(in_ids[0]))\n","\n","  print(\"Done\")\n","  return token_dist_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnpKVhQ9P5L6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595866404987,"user_tz":-330,"elapsed":28210177,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"f2fe99fd-6a5c-4e9b-b92b-65947f937401"},"source":["# pres_token_dist_dict = get_token_dist_dict(uq_lg_data['prescription'], uq_lg_data['label'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4CV1vfiQW0t6","colab_type":"code","colab":{}},"source":["# pres_token_dist_df = pd.DataFrame(pres_token_dist_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ndoUWZXDiop","colab_type":"code","colab":{}},"source":["# pres_token_dist_df.plot(x='index', y='token_count')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7C4btsGQLAE","colab_type":"code","colab":{}},"source":["# pres_token_dist_df.to_csv('data/pres_token_dist_df.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXivUO8JGihl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595867100160,"user_tz":-330,"elapsed":558415,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"c8bd9118-2c10-43db-dbad-c21cd40f17e6"},"source":["# cond_token_dist_dict = get_token_dist_dict(uq_lg_data['condition'], uq_lg_data['label'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jX7lbcTLFXah","colab_type":"code","colab":{}},"source":["# cond_token_dist_df = pd.DataFrame(cond_token_dist_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VlGSHVDxFXX8","colab_type":"code","colab":{}},"source":["# cond_token_dist_df.to_csv('data/cond_token_dist_df.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mkzl0Ra41Wyt","colab_type":"text"},"source":["#### `Task 1`:  Input: Prescription -> Output: Eligibility"]},{"cell_type":"markdown","metadata":{"id":"U4tj-PmQxkTj","colab_type":"text"},"source":["prepare_input() takes considerable amount of time, better save the generated tensors in a dictionary"]},{"cell_type":"code","metadata":{"id":"Mj9p34CRx-OZ","colab_type":"code","colab":{}},"source":["# Uncomment when input needs to reparsed or haven't parsed\n","# remove_input_tensors()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JT9jp8NUPiqG","colab_type":"code","colab":{}},"source":["if not os.path.exists(\"input_tensors/task_1\"):\n","  # Tokenize training and validation data \n","  t1_train_input_ids, t1_train_attention_masks, t1_train_labels = prepare_input(X=fine_pres_elg_X_train, labels=fine_pres_elg_y_train, input_max_len=task1_max_len)\n","  t1_val_input_ids, t1_val_attention_masks, t1_val_labels = prepare_input(X=fine_pres_elg_X_val, labels=fine_pres_elg_y_val, input_max_len=task1_max_len)\n","  # Create Task directory\n","  create_input_tensor_task_dir(task_num=1)\n","  # Create dict map for tensors\n","  t1_input_tensors = {\n","      't1_train_input_ids': t1_train_input_ids,\n","      't1_train_attention_masks': t1_train_attention_masks,\n","      't1_train_labels': t1_train_labels,\n","      't1_val_input_ids': t1_val_input_ids,\n","      't1_val_attention_masks': t1_val_attention_masks,\n","      't1_val_labels': t1_val_labels\n","  }\n","  torch.save(t1_input_tensors, f'input_tensors/task_1/t1_input_tensors')    \n","else:\n","  # input_tensors for task_1 already exist, so we just load them back\n","  t1_input_tensors = torch.load(f'input_tensors/task_1/t1_input_tensors')\n","  t1_train_input_ids = t1_input_tensors['t1_train_input_ids']\n","  t1_train_attention_masks = t1_input_tensors['t1_train_attention_masks']\n","  t1_train_labels = t1_input_tensors['t1_train_labels']\n","  t1_val_input_ids = t1_input_tensors['t1_val_input_ids']\n","  t1_val_attention_masks = t1_input_tensors['t1_val_attention_masks']\n","  t1_val_labels = t1_input_tensors['t1_val_labels']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohCNzudhPi29","colab_type":"code","colab":{}},"source":["# Create Training and Validation Loader\n","_, t1_train_loader = data_wrapper_iterator(input_ids=t1_train_input_ids, attention_masks=t1_train_attention_masks, labels=t1_train_labels, sampler_type=\"random\")\n","_, t1_val_loader = data_wrapper_iterator(input_ids=t1_val_input_ids, attention_masks=t1_val_attention_masks, labels=t1_val_labels, sampler_type=\"sequential\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jI2_t3lfdNPW","colab_type":"code","colab":{}},"source":["t1_num_labels = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFiJUyIlcykf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595804972587,"user_tz":-330,"elapsed":149233,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"c734ba12-36ba-431d-afd8-70d96127dcee"},"source":["# Get object object\n","t1_model = define_classification_model(num_labels=t1_num_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2n7QwJqXcx2B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1595804972597,"user_tz":-330,"elapsed":149217,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"73701619-b293-4733-8213-810ed87561b3"},"source":["# Overview of Model Params\n","print_model_params_overview(model=t1_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eyjt0yPKeLCa","colab_type":"code","colab":{}},"source":["# Intialize Adam(with weight decay fix) optimizer\n","t1_optimizer = get_adam_optimizer(model=t1_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puL-H_bkOTlV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1595804972599,"user_tz":-330,"elapsed":149186,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"9b140231-9f8b-43c3-9fda-679adf34b2a4"},"source":["t1_model, t1_optimizer = amp.initialize(t1_model, t1_optimizer, opt_level='O2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xD4X-dLEeo-f","colab_type":"code","colab":{}},"source":["# Intialize Learning rate scheduler for adam\n","t1_learning_rate_scheduler = get_linear_learning_rate_scheduler(model=t1_model, \n","                                                                optimizer=t1_optimizer, \n","                                                                dataloader=t1_train_loader,\n","                                                                grad_accumulation_steps=model_config['grad_accumulation_steps'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"obh9eNNcfK14","colab_type":"text"},"source":["Finetune t1_model for task 1"]},{"cell_type":"code","metadata":{"id":"sNAJwYwhfrIY","colab_type":"code","colab":{}},"source":["t1_seed_value = 46"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ox9QeJMvysEs","colab_type":"code","colab":{}},"source":["# Function call reference \n","# train(model, train_dataloader, tokenizer, optimizer, scheduler, seed_value, validation_dataloader=None, use_validation=True, grad_accumulation_steps=1, output_dir_name='model_save', save_on_gdrive=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4zVA9IjfQrF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"status":"error","timestamp":1595805340334,"user_tz":-330,"elapsed":516866,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"ab886ada-e854-4d44-bd0f-0ba7797626fb"},"source":["t1_finetune_stats = train(model=t1_model,\n","                       train_dataloader=t1_train_loader,\n","                       tokenizer=tokenizer,\n","                       optimizer=t1_optimizer,\n","                       scheduler=t1_learning_rate_scheduler,\n","                       seed_value=t1_seed_value,\n","                       validation_dataloader=t1_val_loader,\n","                       use_validation=True,\n","                       grad_accumulation_steps=model_config['grad_accumulation_steps'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","========== Epoch 1 / 1 ==========\n","Training...\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["  Batch   300  of  26853.    Elapsed: 0:02:15.\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","  Batch   600  of  26853.    Elapsed: 0:04:26.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-119-adfffc58ae51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                        \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt1_val_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        \u001b[0muse_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                        grad_accumulation_steps=model_config['grad_accumulation_steps'])\n\u001b[0m","\u001b[0;32m<ipython-input-86-517a5426d099>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, tokenizer, optimizer, scheduler, seed_value, validation_dataloader, use_validation, grad_accumulation_steps, output_dir_name, save_on_gdrive)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;31m# Use mixed precision backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0;31m# # Fix for Exploding gradients: Normalize them between 1 and 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"P62v_MiMjEe2","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAc3Ik5QfjKx","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsYY46wD4byx","colab_type":"code","colab":{}},"source":["# tokenizer.encode_plus()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtMhQyDYKHap","colab_type":"code","colab":{}},"source":["# fine_pres_elg_X_train.apply(lambda x: len(x.split()))>400"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljb5vNcmKypq","colab_type":"code","colab":{}},"source":["# fine_pres_elg_X_train[fine_pres_elg_X_train.apply(lambda x: len(x.split())>205)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0in-Qr0X4xFv","colab_type":"code","colab":{}},"source":["# some_dict = tokenizer.encode_plus(\n","#         fine_pres_elg_X_train[9215],\n","#         add_special_tokens = True,    # Add '[CLS]' and '[SEP]'\n","#         max_length = 208,\n","#         truncation=True,\n","#         pad_to_max_length = True,     # Pad & truncate all sentences.\n","#         return_attention_mask = True, # Construct attn. masks.\n","#         return_tensors = 'pt',        # Return pytorch tensors.\n","#     )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oP6Path7Akd","colab_type":"code","colab":{}},"source":["# some_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4wwW_sj6pYC","colab_type":"code","colab":{}},"source":["# tokenizer.encode(fine_pres_elg_X_train[9215], add_special_tokens=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uzx3TRcbmke1","colab_type":"code","colab":{}},"source":["# fine_pres_elg_X_train[9215]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5DXYdyrNsOHs","colab_type":"text"},"source":["## Embeddings"]},{"cell_type":"markdown","metadata":{"id":"fTnUXK1IC1Uz","colab_type":"text"},"source":["Generate BERT sentence embeddings:\n","- Prescription\n","- Condition\n","\n","Embeddings used in:\n","- pres_elg_X_train\n","- pres_elg_X_test\n","- cond_elg_X_train\n","- cond_elg_X_test\n","- cond_intv_X_train\n","- cond_intv_X_test"]},{"cell_type":"code","metadata":{"id":"Nkmf3FetZuMj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1595822184863,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"f3f19cce-c168-4254-b367-40128d846dc3"},"source":["i = 10\n","while (i > 0):\n","  if (i == 5):\n","      i -= 1\n","      continue\n","  print(i)\n","  i -= 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10\n","9\n","8\n","7\n","6\n","4\n","3\n","2\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-3uP_U-hZzxt","colab_type":"code","colab":{}},"source":["def kinetic_energy(m:'in KG', v:'in M/S')-> List['Example']:\n","  trex = 'Example'(1/2*m*v**2)\n","  return [trex for i in range(3)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfmrTGUbdekI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1595823737643,"user_tz":-330,"elapsed":929,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"8333ea63-c645-40cd-db4a-a96aceb27552"},"source":[" kinetic_energy(2, 10)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-bd9f13bd25b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkinetic_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-31-5eaee35dabb0>\u001b[0m in \u001b[0;36mkinetic_energy\u001b[0;34m(m, v)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkinetic_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'in KG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'in M/S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Example'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Example'\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"]}]},{"cell_type":"code","metadata":{"id":"LnRuSReRdhQV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595823602809,"user_tz":-330,"elapsed":859,"user":{"displayName":"Pratik Deoolwadikar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm_ROtGV1QqOCXXiZ8e-3uKpyPdd3dXpyE4NeJww=s64","userId":"12232666687479412064"}},"outputId":"3e0b51fa-e3b2-4120-c482-8adeafd107f1"},"source":["kinetic_energy.__annotations__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'m': 'in KG', 'return': typing.List[_ForwardRef('Example')], 'v': 'in M/S'}"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"vGsfk-E6nBHD","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}